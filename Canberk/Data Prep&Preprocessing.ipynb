{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Negative News Neural Nets Project: Classifying Adverse Media Articles using Machine Learning Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, conda environment with Python 3.86 is used. Some libraries, such as spacy and nltk may require installation if your machine does not have them. \n",
    "\n",
    "You can use the steps below to install spaCy. If something goes awry, feel free to use pip/do some stackoverflow search to complete the installation. The last two parts will be required later on in the notebook, they are not essential spaCy packages.\n",
    "\n",
    " - conda install -c conda-forge spacy\n",
    " \n",
    " - conda install -c conda-forge spacy-lookups-data\n",
    " \n",
    " - python -m spacy download en_core_web_sm\n",
    " \n",
    " - pip install spacy-langdetect\n",
    " \n",
    " - conda install -c conda-forge wordcloud\n",
    " \n",
    "On the other hand, installing nltk packages will be easy, just look at the error to understand what needs to be downloaded using nltk.download(...). I have already provided the download code for punkt package and I don't think anything is required beside that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before doing any EDA, null value imputation, necessary dataset checks etc, we need to form the whole training dataset by combining the AM and NAM articles together. The latter one will include the random articles as well.\n",
    "\n",
    "Let's begin with importing necessary/potentially useful stuff... Some of them below may not be used at all in the future, so the list below is tentative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import spacy\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# For regular expressions\n",
    "import re\n",
    "\n",
    "# For handling strings\n",
    "import string\n",
    "\n",
    "# For performing mathematical operations\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment this if you're using linux\n",
    "# !ls "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C is Win 10\n",
      " Volume Serial Number is CA9A-F06E\n",
      "\n",
      " Directory of C:\\Users\\canberk\\Desktop\\ut-ml-adverse-media-main\n",
      "\n",
      "12/07/2020  05:51 PM    <DIR>          .\n",
      "12/07/2020  05:51 PM    <DIR>          ..\n",
      "11/23/2020  06:08 PM           110,455 .ipynb\n",
      "11/23/2020  06:09 PM    <DIR>          .ipynb_checkpoints\n",
      "11/21/2020  04:43 PM         3,752,073 adverse_media_training.csv.zip\n",
      "11/21/2020  07:29 PM         3,097,536 cleaned&tokenized_text.csv\n",
      "12/07/2020  05:51 PM           134,333 Data Preprocessing&Baselines.ipynb\n",
      "11/21/2020  04:43 PM         3,630,748 EDA - Kristjan's Original.ipynb\n",
      "11/23/2020  06:04 PM         3,740,422 EDA.ipynb\n",
      "10/24/2015  07:35 PM     5,646,236,541 glove.840B.300d.txt\n",
      "12/07/2020  04:36 PM     2,176,768,927 glove.840B.300d.zip\n",
      "11/21/2020  04:43 PM             1,073 LICENSE\n",
      "11/21/2020  04:43 PM         3,764,231 non_adverse_media_training.csv.zip\n",
      "11/21/2020  04:43 PM                21 README.md\n",
      "              11 File(s)  7,841,236,360 bytes\n",
      "               3 Dir(s)  21,480,312,832 bytes free\n"
     ]
    }
   ],
   "source": [
    "# Let's get an overview of what our folder contains..\n",
    "!dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the data required are in zipped format. Let's read them with pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "am = pd.read_csv('adverse_media_training.csv.zip')\n",
    "nam = pd.read_csv('non_adverse_media_training.csv.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the labels in both datasets. We may(/will :)) encounter some typos among them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan 'am' 'delete' 'delete        ' 'random' 'nam' 'doubt' 'neither'\n",
      " 'am, doubt' 'am ']\n",
      "\n",
      "am                391\n",
      "delete             32\n",
      "nam                18\n",
      "random             12\n",
      "doubt               5\n",
      "neither             2\n",
      "delete              2\n",
      "am, doubt           1\n",
      "am                  1\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(am.label.unique())\n",
    "print()\n",
    "print(am.label.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['nam' nan 'am' 'neither' 'random' 'doubt' 'delete']\n",
      "\n",
      "nam        285\n",
      "am          19\n",
      "doubt       13\n",
      "delete       9\n",
      "neither      7\n",
      "random       3\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(nam.label.unique())\n",
    "print()\n",
    "print(nam.label.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both datasets are not pure in their essence. We need to transfer some rows between them and drop the unnecessary rows having labels such as 'delete', 'neither' etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(411, 11)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating the AM dataset for train\n",
    "am_confirmed = am.loc[(am.label == 'am') | (am.label == 'am ')]\n",
    "am_confirmed = pd.concat([am_confirmed, nam.loc[nam.label == 'am']])\n",
    "am_confirmed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(318, 11)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating NAM dataset for train\n",
    "nam_confirmed = nam.loc[(nam.label == 'nam') | (nam.label == 'random')]\n",
    "nam_confirmed = pd.concat([nam_confirmed, am.loc[(am.label == 'nam') | (am.label == 'random')]])\n",
    "nam_confirmed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us also append the necessary labels. Actually, we can also modify the label column in both datasets directly.\n",
    "am_confirmed['is_adverse_media'] = 1\n",
    "nam_confirmed['is_adverse_media'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(729, 12)\n",
      "\n",
      "1    411\n",
      "0    318\n",
      "Name: is_adverse_media, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Creating the train dataset\n",
    "train = pd.concat([am_confirmed, nam_confirmed])\n",
    "print(train.shape)\n",
    "print()\n",
    "print(train['is_adverse_media'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratio of AM to NAM articles: 1.29\n"
     ]
    }
   ],
   "source": [
    "# Ratio of AM to NAM class\n",
    "print('Ratio of AM to NAM articles:', round(411/318, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our dataset may turn out to be small for now, but thankfully it is not imbalanced very much. \n",
    "\n",
    "**After adding Oskar's json data, dataset imbalance will be a problem.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anyway, let's take a quick look into what type of columns the train set has, and get some sumamry statistics on the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 729 entries, 8 to 773\n",
      "Data columns (total 12 columns):\n",
      "source              729 non-null object\n",
      "entity_name         630 non-null object\n",
      "entity_type         631 non-null object\n",
      "url                 729 non-null object\n",
      "article             729 non-null object\n",
      "full_response       729 non-null object\n",
      "label               729 non-null object\n",
      "explanation         633 non-null object\n",
      "assessor            727 non-null object\n",
      "comment             23 non-null object\n",
      "title               729 non-null object\n",
      "is_adverse_media    729 non-null int64\n",
      "dtypes: int64(1), object(11)\n",
      "memory usage: 74.0+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    729.000000\n",
       "mean       0.563786\n",
       "std        0.496255\n",
       "min        0.000000\n",
       "25%        0.000000\n",
       "50%        1.000000\n",
       "75%        1.000000\n",
       "max        1.000000\n",
       "Name: is_adverse_media, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.is_adverse_media.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our basic task is to classify text articles, we will need the *article* and *is_adverse_media* columns for the sentiment analysis task. \n",
    "\n",
    "Later on, if we decide to add an entity recognition task or turn this into a multilabel classification problem, we will need some other columns like *entity_name* as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Until now, we have created the training dataset in its crude form. In this part we will filter the training data and check the articles column for null values or non-english text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>entity_name</th>\n",
       "      <th>entity_type</th>\n",
       "      <th>url</th>\n",
       "      <th>article</th>\n",
       "      <th>full_response</th>\n",
       "      <th>label</th>\n",
       "      <th>explanation</th>\n",
       "      <th>assessor</th>\n",
       "      <th>comment</th>\n",
       "      <th>title</th>\n",
       "      <th>is_adverse_media</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>Canberk</td>\n",
       "      <td>Sam Waksal</td>\n",
       "      <td>Person</td>\n",
       "      <td>http://content.time.com/time/specials/packages...</td>\n",
       "      <td>Bernie Madoff, who is scheduled to be sentence...</td>\n",
       "      <td>[{'error': 'Proxy error: msgtimeout', 'query':...</td>\n",
       "      <td>am</td>\n",
       "      <td>fraud</td>\n",
       "      <td>Carel</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Top 10 Crooked CEOs</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>Dan</td>\n",
       "      <td>Mark Denning</td>\n",
       "      <td>Person</td>\n",
       "      <td>https://www.bbc.com/news/business-50089887</td>\n",
       "      <td>Published\\n\\nOne of the world's leading fund m...</td>\n",
       "      <td>[{'query': {'id': '1605053818341-a38bb1c20fc7b...</td>\n",
       "      <td>am</td>\n",
       "      <td>broke investment rules</td>\n",
       "      <td>Wanting</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Top fund manager forced to resign after BBC in...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>Darya</td>\n",
       "      <td>Russell Wasendorf Sr</td>\n",
       "      <td>individual</td>\n",
       "      <td>https://www.bbc.com/news/business-19631611</td>\n",
       "      <td>Published\\n\\nThe founder of US futures broker ...</td>\n",
       "      <td>[{'query': {'id': '1605055958079-99347130d4bde...</td>\n",
       "      <td>am</td>\n",
       "      <td>pleads guilty to fraud</td>\n",
       "      <td>Sebastien</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Peregrine Financial Group boss admits $100m fraud</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>Karl</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://apnews.com/article/9acaa6485cbe480d843...</td>\n",
       "      <td>WASHINGTON (AP) — An American security contrac...</td>\n",
       "      <td>[{'query': {'id': '1605050186817-549afd2bcf473...</td>\n",
       "      <td>am</td>\n",
       "      <td>Corruption, multiple people</td>\n",
       "      <td>Karl</td>\n",
       "      <td>NaN</td>\n",
       "      <td>American accuses Congo officials of unlawful a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>Canberk</td>\n",
       "      <td>Charlie Shrem</td>\n",
       "      <td>Person</td>\n",
       "      <td>https://www.theguardian.com/technology/2014/ja...</td>\n",
       "      <td>A senior figure in the Bitcoin Foundation, whi...</td>\n",
       "      <td>[{'query': {'id': '1605374115413-cdb55925327dd...</td>\n",
       "      <td>am</td>\n",
       "      <td>arrested for money launering</td>\n",
       "      <td>Sebastien</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bitcoin Foundation vice chair arrested for mon...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     source           entity_name entity_type  \\\n",
       "8   Canberk            Sam Waksal      Person   \n",
       "10      Dan          Mark Denning      Person   \n",
       "11    Darya  Russell Wasendorf Sr  individual   \n",
       "12     Karl                   NaN         NaN   \n",
       "17  Canberk         Charlie Shrem      Person   \n",
       "\n",
       "                                                  url  \\\n",
       "8   http://content.time.com/time/specials/packages...   \n",
       "10         https://www.bbc.com/news/business-50089887   \n",
       "11         https://www.bbc.com/news/business-19631611   \n",
       "12  https://apnews.com/article/9acaa6485cbe480d843...   \n",
       "17  https://www.theguardian.com/technology/2014/ja...   \n",
       "\n",
       "                                              article  \\\n",
       "8   Bernie Madoff, who is scheduled to be sentence...   \n",
       "10  Published\\n\\nOne of the world's leading fund m...   \n",
       "11  Published\\n\\nThe founder of US futures broker ...   \n",
       "12  WASHINGTON (AP) — An American security contrac...   \n",
       "17  A senior figure in the Bitcoin Foundation, whi...   \n",
       "\n",
       "                                        full_response label  \\\n",
       "8   [{'error': 'Proxy error: msgtimeout', 'query':...    am   \n",
       "10  [{'query': {'id': '1605053818341-a38bb1c20fc7b...    am   \n",
       "11  [{'query': {'id': '1605055958079-99347130d4bde...    am   \n",
       "12  [{'query': {'id': '1605050186817-549afd2bcf473...    am   \n",
       "17  [{'query': {'id': '1605374115413-cdb55925327dd...    am   \n",
       "\n",
       "                     explanation   assessor comment  \\\n",
       "8                          fraud      Carel     NaN   \n",
       "10        broke investment rules    Wanting     NaN   \n",
       "11        pleads guilty to fraud  Sebastien     NaN   \n",
       "12   Corruption, multiple people       Karl     NaN   \n",
       "17  arrested for money launering  Sebastien     NaN   \n",
       "\n",
       "                                                title  is_adverse_media  \n",
       "8                                 Top 10 Crooked CEOs                 1  \n",
       "10  Top fund manager forced to resign after BBC in...                 1  \n",
       "11  Peregrine Financial Group boss admits $100m fraud                 1  \n",
       "12  American accuses Congo officials of unlawful a...                 1  \n",
       "17  Bitcoin Foundation vice chair arrested for mon...                 1  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's drop the unnecessary columns from the training dataset. \n",
    "\n",
    "(**Question for Kristjan:** Do the columns 'url, full_response and title' necessary for any other extra analysis in the future?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity_name</th>\n",
       "      <th>entity_type</th>\n",
       "      <th>url</th>\n",
       "      <th>article</th>\n",
       "      <th>full_response</th>\n",
       "      <th>explanation</th>\n",
       "      <th>title</th>\n",
       "      <th>is_adverse_media</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>630</td>\n",
       "      <td>631</td>\n",
       "      <td>729</td>\n",
       "      <td>729</td>\n",
       "      <td>729</td>\n",
       "      <td>633</td>\n",
       "      <td>729</td>\n",
       "      <td>729.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>unique</td>\n",
       "      <td>483</td>\n",
       "      <td>16</td>\n",
       "      <td>729</td>\n",
       "      <td>729</td>\n",
       "      <td>729</td>\n",
       "      <td>370</td>\n",
       "      <td>723</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>top</td>\n",
       "      <td>John McAfee</td>\n",
       "      <td>individual</td>\n",
       "      <td>https://www.civilserviceindia.com/subject/Gene...</td>\n",
       "      <td>Banks have given a cautious welcome to US move...</td>\n",
       "      <td>[{'query': {'id': '1605044480200-60ffcd0dc7f34...</td>\n",
       "      <td>corruption</td>\n",
       "      <td>Ministry of Justice calls upon law firms to ta...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>freq</td>\n",
       "      <td>8</td>\n",
       "      <td>185</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.563786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.496255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        entity_name entity_type  \\\n",
       "count           630         631   \n",
       "unique          483          16   \n",
       "top     John McAfee  individual   \n",
       "freq              8         185   \n",
       "mean            NaN         NaN   \n",
       "std             NaN         NaN   \n",
       "min             NaN         NaN   \n",
       "25%             NaN         NaN   \n",
       "50%             NaN         NaN   \n",
       "75%             NaN         NaN   \n",
       "max             NaN         NaN   \n",
       "\n",
       "                                                      url  \\\n",
       "count                                                 729   \n",
       "unique                                                729   \n",
       "top     https://www.civilserviceindia.com/subject/Gene...   \n",
       "freq                                                    1   \n",
       "mean                                                  NaN   \n",
       "std                                                   NaN   \n",
       "min                                                   NaN   \n",
       "25%                                                   NaN   \n",
       "50%                                                   NaN   \n",
       "75%                                                   NaN   \n",
       "max                                                   NaN   \n",
       "\n",
       "                                                  article  \\\n",
       "count                                                 729   \n",
       "unique                                                729   \n",
       "top     Banks have given a cautious welcome to US move...   \n",
       "freq                                                    1   \n",
       "mean                                                  NaN   \n",
       "std                                                   NaN   \n",
       "min                                                   NaN   \n",
       "25%                                                   NaN   \n",
       "50%                                                   NaN   \n",
       "75%                                                   NaN   \n",
       "max                                                   NaN   \n",
       "\n",
       "                                            full_response explanation  \\\n",
       "count                                                 729         633   \n",
       "unique                                                729         370   \n",
       "top     [{'query': {'id': '1605044480200-60ffcd0dc7f34...  corruption   \n",
       "freq                                                    1          34   \n",
       "mean                                                  NaN         NaN   \n",
       "std                                                   NaN         NaN   \n",
       "min                                                   NaN         NaN   \n",
       "25%                                                   NaN         NaN   \n",
       "50%                                                   NaN         NaN   \n",
       "75%                                                   NaN         NaN   \n",
       "max                                                   NaN         NaN   \n",
       "\n",
       "                                                    title  is_adverse_media  \n",
       "count                                                 729        729.000000  \n",
       "unique                                                723               NaN  \n",
       "top     Ministry of Justice calls upon law firms to ta...               NaN  \n",
       "freq                                                    2               NaN  \n",
       "mean                                                  NaN          0.563786  \n",
       "std                                                   NaN          0.496255  \n",
       "min                                                   NaN          0.000000  \n",
       "25%                                                   NaN          0.000000  \n",
       "50%                                                   NaN          1.000000  \n",
       "75%                                                   NaN          1.000000  \n",
       "max                                                   NaN          1.000000  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Keep only needed columns\n",
    "train = train.loc[:, ['entity_name', 'entity_type', 'url', 'article', 'full_response', 'explanation', 'title', 'is_adverse_media']]\n",
    "\n",
    "train.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can narrow our focus a little bit more... Let's check if there are any nulls in article & is_adverse_media columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(train.article.isna()), sum(train.is_adverse_media.isna())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We gotta do one last check before tokenizing the articles, we need to check if there are any non-english text managed to slip in during the data collection process. spaCy can do this with its langdetect module, hope you succeeded in installing it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install spacy-langdetect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'language': 'et', 'score': 0.9999948922362369}\n",
      "This is an english text. {'language': 'en', 'score': 0.9999966325242425}\n",
      "Ja see on eestikeelne lause. {'language': 'et', 'score': 0.9999937782572812}\n",
      "بوغيث\t {'language': 'ar', 'score': 0.9999945969262914}\n"
     ]
    }
   ],
   "source": [
    "# Make sure we only have English articles\n",
    "from spacy_langdetect import LanguageDetector\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "nlp.add_pipe(LanguageDetector(), name='language_detector', last=True)\n",
    "\n",
    "# Let's create an example doc object first to test spaCy's LanguageDetector.\n",
    "text = 'This is an english text. Ja see on eestikeelne lause. بوغيث\t'\n",
    "doc = nlp(text)\n",
    "# document level language detection. Think of it like average language of the document!\n",
    "print(doc._.language)\n",
    "# sentence level language detection\n",
    "for sent in doc.sents:\n",
    "    print(sent, sent._.language)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The language detector acts like a weirdo while trying to understand the average language of the document. Classifying the whole text as 85 percent Estonian is a bit too much in my opinion. Let's test it on an actual article in the train dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Bernie Madoff, who is scheduled to be sentenced June 29 for perpetrating history's biggest Ponzi scheme, is just be the latest in a long line of industry titans turned crooks\\n\\nCRIMINAL EXECUTIVE OFFICER\\nSam Waksal\\n\\nCEO:\\xa0ImClone\\nConvicted: October 15, 2002 of securities fraud, bank fraud, obstruction of justice, and perjury\\nKnown for his networking skills as much as for his scientific expertise, immunologist Sam Waksal founded ImClone in 1984. The New York-based biotech firm remained relatively unknown until 1999, when it announced the creation of Erbitux — a cancer-fighting drug so promising it convinced pharmaceutical giant Bristol-Myers to purchase $1 billion of ImClone stock in one of the largest biotechnology partnerships in U.S. history. But when the Food and Drug Administration rejected the drug, Waksal alerted several relatives and friends to dump their stock as soon as possible — before the FDA's decision had been made public. Waksal's father and daughter sold $9.2 million worth of ImClone, a move that caught the attention of the SEC and eventually led to his arrest.\\nThough Waksal pleaded guilty and publicly apologized to his family, his colleagues, and the millions of cancer patients who had held such high hopes for Erbitux, Judge William Pauley dismissed calls for leniency, noting that Waksal had contributed a mere one-half of 1 percent of his $133 million fortune to charity. In the end, the fallen entrepreneur paid $4.3 million in fines and tax restitution, and served 87 months in prison; he was released on Feb. 9, 2009. The scandal's most infamous casualty, however, turned out to be Waksal's pal, Martha Stewart, who had unloaded all 3,928 of her company shares just days before the FDA's decision had been announced to avoid losing an estimated $45,673; the domestic diva got five months in prison as a result.\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = train.article[8]\n",
    "example # Clearly this one's in English."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'language': 'en', 'score': 0.9999962549118911}\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(example)\n",
    "print(doc._.language)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With long texts like the articles we collected, spaCy does a good job.\n",
    "\n",
    "Now, let's check the whole dataset to see if any non-english article exists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['en'], dtype=object)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['article'].apply(lambda article: nlp(article)._.language['language']).unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of our articles are in English. We can now move on to creating tokens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before applying any vectorizer, we need to create tokens from our articles by cleaning them from punctuation, empty spaces etc. The helper function below will use some regex commands to handle all those, besides transforming all the letters to lowercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The regex below can be modified later on.\n",
    "def lemmatize(article):\n",
    "    article = re.sub(r'http\\S+', '', article)\n",
    "    article = re.sub(r\"#(\\w+)\", '', article)\n",
    "    article = re.sub(r\"@(\\w+)\", '', article)\n",
    "    article = re.sub(r'[^\\w\\s]', '', article)\n",
    "    article = re.sub(r'\\w*\\d\\w*','', article)\n",
    "    article = re.sub(' +',' ', article)\n",
    "    article = article.strip().lower()\n",
    "    \n",
    "    nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
    "    doc = nlp(article)\n",
    "    lemmatized_article = \" \".join([token.lemma_ for token in doc if (token.is_stop==False)]) \n",
    "    \n",
    "    return lemmatized_article"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, let's use the lemmatize function on an example to see what it does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Lemmatization:\n",
      "\n",
      "Bernie Madoff, who is scheduled to be sentenced June 29 for perpetrating history's biggest Ponzi scheme, is just be the latest in a long line of industry titans turned crooks\n",
      "\n",
      "CRIMINAL EXECUTIVE OFFICER\n",
      "Sam Waksal\n",
      "\n",
      "CEO: ImClone\n",
      "Convicted: October 15, 2002 of securities fraud, bank fraud, obstruction of justice, and perjury\n",
      "Known for his networking skills as much as for his scientific expertise, immunologist Sam Waksal founded ImClone in 1984. The New York-based biotech firm remained relatively unknown until 1999, when it announced the creation of Erbitux — a cancer-fighting drug so promising it convinced pharmaceutical giant Bristol-Myers to purchase $1 billion of ImClone stock in one of the largest biotechnology partnerships in U.S. history. But when the Food and Drug Administration rejected the drug, Waksal alerted several relatives and friends to dump their stock as soon as possible — before the FDA's decision had been made public. Waksal's father and daughter sold $9.2 million worth of ImClone, a move that caught the attention of the SEC and eventually led to his arrest.\n",
      "Though Waksal pleaded guilty and publicly apologized to his family, his colleagues, and the millions of cancer patients who had held such high hopes for Erbitux, Judge William Pauley dismissed calls for leniency, noting that Waksal had contributed a mere one-half of 1 percent of his $133 million fortune to charity. In the end, the fallen entrepreneur paid $4.3 million in fines and tax restitution, and served 87 months in prison; he was released on Feb. 9, 2009. The scandal's most infamous casualty, however, turned out to be Waksal's pal, Martha Stewart, who had unloaded all 3,928 of her company shares just days before the FDA's decision had been announced to avoid losing an estimated $45,673; the domestic diva got five months in prison as a result.\n",
      "\n",
      "After Lemmatization:\n",
      "\n",
      "bernie madoff schedule sentence june perpetrate historys big ponzi scheme late long line industry titan turn crook \n",
      "\n",
      " criminal executive officer \n",
      " sam waksal \n",
      "\n",
      " ceo    imclone \n",
      " convict october securities fraud bank fraud obstruction justice perjury \n",
      " know networking skill scientific expertise immunologist sam waksal found imclone new yorkbase biotech firm remain relatively unknown announce creation erbitux cancerfighte drug promise convince pharmaceutical giant bristolmyer purchase billion imclone stock large biotechnology partnership history food drug administration reject drug waksal alert relative friend dump stock soon possible fdas decision public waksal father daughter sell million worth imclone catch attention sec eventually lead arrest \n",
      " waksal plead guilty publicly apologize family colleague million cancer patient hold high hope erbitux judge william pauley dismiss call leniency note waksal contribute mere onehalf percent million fortune charity end fall entrepreneur pay million fine tax restitution serve month prison release feb scandal infamous casualty turn waksal pal martha stewart unload company share day fdas decision announce avoid lose estimate domestic diva get month prison result\n",
      "\n"
     ]
    }
   ],
   "source": [
    "example = train.article[8]\n",
    "lemmatized = lemmatize(example)\n",
    "\n",
    "print('Before Lemmatization:')\n",
    "print()\n",
    "print(example)\n",
    "print()\n",
    "\n",
    "print('After Lemmatization:')\n",
    "print()\n",
    "print(lemmatized)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's copy our train data and apply lemmatization on the articles belonging to the copy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of our DataFrame: (729, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article</th>\n",
       "      <th>is_adverse_media</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Bernie Madoff, who is scheduled to be sentence...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Published\\n\\nOne of the world's leading fund m...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Published\\n\\nThe founder of US futures broker ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>WASHINGTON (AP) — An American security contrac...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>A senior figure in the Bitcoin Foundation, whi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             article  is_adverse_media\n",
       "0  Bernie Madoff, who is scheduled to be sentence...                 1\n",
       "1  Published\\n\\nOne of the world's leading fund m...                 1\n",
       "2  Published\\n\\nThe founder of US futures broker ...                 1\n",
       "3  WASHINGTON (AP) — An American security contrac...                 1\n",
       "4  A senior figure in the Bitcoin Foundation, whi...                 1"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = train[['article', 'is_adverse_media']].copy()\n",
    "data = data.reset_index()\n",
    "data = data.drop(['index'], axis=1)\n",
    "print('Shape of our DataFrame:', data.shape)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article</th>\n",
       "      <th>is_adverse_media</th>\n",
       "      <th>lemmatized_articles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Bernie Madoff, who is scheduled to be sentence...</td>\n",
       "      <td>1</td>\n",
       "      <td>bernie madoff schedule sentence june perpetrat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Published\\n\\nOne of the world's leading fund m...</td>\n",
       "      <td>1</td>\n",
       "      <td>publish \\n\\n world lead fund manager force res...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Published\\n\\nThe founder of US futures broker ...</td>\n",
       "      <td>1</td>\n",
       "      <td>publish \\n\\n founder future broker peregrine f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>WASHINGTON (AP) — An American security contrac...</td>\n",
       "      <td>1</td>\n",
       "      <td>washington ap american security contractor acc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>A senior figure in the Bitcoin Foundation, whi...</td>\n",
       "      <td>1</td>\n",
       "      <td>senior figure bitcoin foundation lobby behalf ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             article  is_adverse_media  \\\n",
       "0  Bernie Madoff, who is scheduled to be sentence...                 1   \n",
       "1  Published\\n\\nOne of the world's leading fund m...                 1   \n",
       "2  Published\\n\\nThe founder of US futures broker ...                 1   \n",
       "3  WASHINGTON (AP) — An American security contrac...                 1   \n",
       "4  A senior figure in the Bitcoin Foundation, whi...                 1   \n",
       "\n",
       "                                 lemmatized_articles  \n",
       "0  bernie madoff schedule sentence june perpetrat...  \n",
       "1  publish \\n\\n world lead fund manager force res...  \n",
       "2  publish \\n\\n founder future broker peregrine f...  \n",
       "3  washington ap american security contractor acc...  \n",
       "4  senior figure bitcoin foundation lobby behalf ...  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['lemmatized_articles'] = data['article'].map(lemmatize)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of our DataFrame: (729, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_adverse_media</th>\n",
       "      <th>lemmatized_articles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>481</td>\n",
       "      <td>0</td>\n",
       "      <td>fraud manager access seon new intelligence too...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>214</td>\n",
       "      <td>1</td>\n",
       "      <td>washington ap treasury name mob boss italys ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1</td>\n",
       "      <td>\\n\\n  min read \\n\\n miami reuters court senten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>306</td>\n",
       "      <td>1</td>\n",
       "      <td>san diego rabbi yisroel goldstein director cha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>721</td>\n",
       "      <td>0</td>\n",
       "      <td>nauru bank field mineralrich smooth brown rock...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     is_adverse_media                                lemmatized_articles\n",
       "481                 0  fraud manager access seon new intelligence too...\n",
       "214                 1  washington ap treasury name mob boss italys ca...\n",
       "110                 1  \\n\\n  min read \\n\\n miami reuters court senten...\n",
       "306                 1  san diego rabbi yisroel goldstein director cha...\n",
       "721                 0  nauru bank field mineralrich smooth brown rock..."
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data[['is_adverse_media', 'lemmatized_articles']] # These are the only columns that we need for modeling\n",
    "data = data.sample(frac = 1) # Let us not forget to shuffle the rows before train_test_split\n",
    "\n",
    "print('Shape of our DataFrame:', data.shape)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's save this cleaned dataframe as a csv file for later usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't run this line again, the csv file is already created. This is just for explanatory purposes.\n",
    "# data[['is_adverse_media', 'lemmatized_articles']].to_csv('./cleaned_lemmatized_text.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
