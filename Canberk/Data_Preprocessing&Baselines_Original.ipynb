{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Negative News Neural Nets Project: Classifying Adverse Media Articles using Machine Learning Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just use pipenv install to install all the neede packages in Pipfile. You can read all about pipenv at https://pipenv.pypa.io/en/latest/\n",
    "\n",
    "Installing nltk packages will be easy, just look at the error to understand what needs to be downloaded using nltk.download(...). I have already provided the download code for punkt package and I don't think anything is required beside that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before doing any EDA, null value imputation, necessary dataset checks etc, we need to form the whole training dataset by combining the AM and NAM articles together. The latter one will include the random articles as well.\n",
    "\n",
    "Let's begin with importing necessary/potentially useful stuff... Some of them below may not be used at all in the future, so the list below is tentative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# For regular expressions\n",
    "import re\n",
    "\n",
    "# For handling strings\n",
    "import string\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, auc, roc_auc_score, f1_score, confusion_matrix\n",
    "import joblib\n",
    "\n",
    "import scipy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For nlp to work you need to \n",
    "`pipenv shell`\n",
    "and then\n",
    "`python -m spacy download en_core_web_sm`\n",
    "\n",
    "in the terminal/command line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data-PreprocessingBaselines.ipynb Pipfile.lock\n",
      "Pipfile\n"
     ]
    }
   ],
   "source": [
    "# Uncomment this if you're using linux\n",
    "!ls "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's get an overview of what our folder contains..\n",
    "#!dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the data required are in zipped format. Let's read them with pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "am = pd.read_csv('../../adverse_media_training.csv')\n",
    "nam = pd.read_csv('../../non_adverse_media_training.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the labels in both datasets. We may(/will :)) encounter some typos among them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan 'am' 'delete' 'delete        ' 'random' 'nam' 'doubt' 'neither'\n",
      " 'am, doubt' 'am ']\n",
      "\n",
      "am                391\n",
      "delete             32\n",
      "nam                18\n",
      "random             12\n",
      "doubt               5\n",
      "delete              2\n",
      "neither             2\n",
      "am, doubt           1\n",
      "am                  1\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(am.label.unique())\n",
    "print()\n",
    "print(am.label.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['nam' nan 'am' 'neither' 'random' 'doubt' 'delete']\n",
      "\n",
      "nam        285\n",
      "am          19\n",
      "doubt       13\n",
      "delete       9\n",
      "neither      7\n",
      "random       3\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(nam.label.unique())\n",
    "print()\n",
    "print(nam.label.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both datasets are not pure in their essence. We need to transfer some rows between them and drop the unnecessary rows having labels such as 'delete', 'neither' etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(411, 11)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating the AM dataset for train\n",
    "am_confirmed = am.loc[(am.label == 'am') | (am.label == 'am ')]\n",
    "am_confirmed = pd.concat([am_confirmed, nam.loc[nam.label == 'am']])\n",
    "am_confirmed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(318, 11)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating NAM dataset for train\n",
    "nam_confirmed = nam.loc[(nam.label == 'nam') | (nam.label == 'random')]\n",
    "nam_confirmed = pd.concat([nam_confirmed, am.loc[(am.label == 'nam') | (am.label == 'random')]])\n",
    "nam_confirmed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us also append the necessary labels. Actually, we can also modify the label column in both datasets directly.\n",
    "am_confirmed['is_adverse_media'] = 1\n",
    "nam_confirmed['is_adverse_media'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(729, 12)\n",
      "\n",
      "1    411\n",
      "0    318\n",
      "Name: is_adverse_media, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Creating the train dataset\n",
    "train = pd.concat([am_confirmed, nam_confirmed])\n",
    "print(train.shape)\n",
    "print()\n",
    "print(train['is_adverse_media'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratio of AM to NAM articles: 1.29\n"
     ]
    }
   ],
   "source": [
    "# Ratio of AM to NAM class\n",
    "print('Ratio of AM to NAM articles:', round(411/318, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our dataset may turn out to be small for now, but thankfully it is not imbalanced very much. \n",
    "\n",
    "**After adding Oskar's json data, dataset imbalance will be a problem.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anyway, let's take a quick look into what type of columns the train set has, and get some sumamry statistics on the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 729 entries, 8 to 773\n",
      "Data columns (total 12 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   source            729 non-null    object\n",
      " 1   entity_name       630 non-null    object\n",
      " 2   entity_type       631 non-null    object\n",
      " 3   url               729 non-null    object\n",
      " 4   article           729 non-null    object\n",
      " 5   full_response     729 non-null    object\n",
      " 6   label             729 non-null    object\n",
      " 7   explanation       633 non-null    object\n",
      " 8   assessor          727 non-null    object\n",
      " 9   comment           23 non-null     object\n",
      " 10  title             729 non-null    object\n",
      " 11  is_adverse_media  729 non-null    int64 \n",
      "dtypes: int64(1), object(11)\n",
      "memory usage: 74.0+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    729.000000\n",
       "mean       0.563786\n",
       "std        0.496255\n",
       "min        0.000000\n",
       "25%        0.000000\n",
       "50%        1.000000\n",
       "75%        1.000000\n",
       "max        1.000000\n",
       "Name: is_adverse_media, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.is_adverse_media.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our basic task is to classify text articles, we will need the *article* and *is_adverse_media* columns for the sentiment analysis task. \n",
    "\n",
    "Later on, if we decide to add an entity recognition task or turn this into a multilabel classification problem, we will need some other columns like *entity_name* as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Until now, we have created the training dataset in its crude form. In this part we will filter the training data and check the articles column for null values or non-english text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>entity_name</th>\n",
       "      <th>entity_type</th>\n",
       "      <th>url</th>\n",
       "      <th>article</th>\n",
       "      <th>full_response</th>\n",
       "      <th>label</th>\n",
       "      <th>explanation</th>\n",
       "      <th>assessor</th>\n",
       "      <th>comment</th>\n",
       "      <th>title</th>\n",
       "      <th>is_adverse_media</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Canberk</td>\n",
       "      <td>Sam Waksal</td>\n",
       "      <td>Person</td>\n",
       "      <td>http://content.time.com/time/specials/packages...</td>\n",
       "      <td>Bernie Madoff, who is scheduled to be sentence...</td>\n",
       "      <td>[{'error': 'Proxy error: msgtimeout', 'query':...</td>\n",
       "      <td>am</td>\n",
       "      <td>fraud</td>\n",
       "      <td>Carel</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Top 10 Crooked CEOs</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Dan</td>\n",
       "      <td>Mark Denning</td>\n",
       "      <td>Person</td>\n",
       "      <td>https://www.bbc.com/news/business-50089887</td>\n",
       "      <td>Published\\n\\nOne of the world's leading fund m...</td>\n",
       "      <td>[{'query': {'id': '1605053818341-a38bb1c20fc7b...</td>\n",
       "      <td>am</td>\n",
       "      <td>broke investment rules</td>\n",
       "      <td>Wanting</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Top fund manager forced to resign after BBC in...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Darya</td>\n",
       "      <td>Russell Wasendorf Sr</td>\n",
       "      <td>individual</td>\n",
       "      <td>https://www.bbc.com/news/business-19631611</td>\n",
       "      <td>Published\\n\\nThe founder of US futures broker ...</td>\n",
       "      <td>[{'query': {'id': '1605055958079-99347130d4bde...</td>\n",
       "      <td>am</td>\n",
       "      <td>pleads guilty to fraud</td>\n",
       "      <td>Sebastien</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Peregrine Financial Group boss admits $100m fraud</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Karl</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://apnews.com/article/9acaa6485cbe480d843...</td>\n",
       "      <td>WASHINGTON (AP) — An American security contrac...</td>\n",
       "      <td>[{'query': {'id': '1605050186817-549afd2bcf473...</td>\n",
       "      <td>am</td>\n",
       "      <td>Corruption, multiple people</td>\n",
       "      <td>Karl</td>\n",
       "      <td>NaN</td>\n",
       "      <td>American accuses Congo officials of unlawful a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Canberk</td>\n",
       "      <td>Charlie Shrem</td>\n",
       "      <td>Person</td>\n",
       "      <td>https://www.theguardian.com/technology/2014/ja...</td>\n",
       "      <td>A senior figure in the Bitcoin Foundation, whi...</td>\n",
       "      <td>[{'query': {'id': '1605374115413-cdb55925327dd...</td>\n",
       "      <td>am</td>\n",
       "      <td>arrested for money launering</td>\n",
       "      <td>Sebastien</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bitcoin Foundation vice chair arrested for mon...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     source           entity_name entity_type  \\\n",
       "8   Canberk            Sam Waksal      Person   \n",
       "10      Dan          Mark Denning      Person   \n",
       "11    Darya  Russell Wasendorf Sr  individual   \n",
       "12     Karl                   NaN         NaN   \n",
       "17  Canberk         Charlie Shrem      Person   \n",
       "\n",
       "                                                  url  \\\n",
       "8   http://content.time.com/time/specials/packages...   \n",
       "10         https://www.bbc.com/news/business-50089887   \n",
       "11         https://www.bbc.com/news/business-19631611   \n",
       "12  https://apnews.com/article/9acaa6485cbe480d843...   \n",
       "17  https://www.theguardian.com/technology/2014/ja...   \n",
       "\n",
       "                                              article  \\\n",
       "8   Bernie Madoff, who is scheduled to be sentence...   \n",
       "10  Published\\n\\nOne of the world's leading fund m...   \n",
       "11  Published\\n\\nThe founder of US futures broker ...   \n",
       "12  WASHINGTON (AP) — An American security contrac...   \n",
       "17  A senior figure in the Bitcoin Foundation, whi...   \n",
       "\n",
       "                                        full_response label  \\\n",
       "8   [{'error': 'Proxy error: msgtimeout', 'query':...    am   \n",
       "10  [{'query': {'id': '1605053818341-a38bb1c20fc7b...    am   \n",
       "11  [{'query': {'id': '1605055958079-99347130d4bde...    am   \n",
       "12  [{'query': {'id': '1605050186817-549afd2bcf473...    am   \n",
       "17  [{'query': {'id': '1605374115413-cdb55925327dd...    am   \n",
       "\n",
       "                     explanation   assessor comment  \\\n",
       "8                          fraud      Carel     NaN   \n",
       "10        broke investment rules    Wanting     NaN   \n",
       "11        pleads guilty to fraud  Sebastien     NaN   \n",
       "12   Corruption, multiple people       Karl     NaN   \n",
       "17  arrested for money launering  Sebastien     NaN   \n",
       "\n",
       "                                                title  is_adverse_media  \n",
       "8                                 Top 10 Crooked CEOs                 1  \n",
       "10  Top fund manager forced to resign after BBC in...                 1  \n",
       "11  Peregrine Financial Group boss admits $100m fraud                 1  \n",
       "12  American accuses Congo officials of unlawful a...                 1  \n",
       "17  Bitcoin Foundation vice chair arrested for mon...                 1  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's drop the unnecessary columns from the training dataset. \n",
    "\n",
    "(**Question for Kristjan:** Do the columns 'url, full_response and title' necessary for any other extra analysis in the future?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity_name</th>\n",
       "      <th>entity_type</th>\n",
       "      <th>url</th>\n",
       "      <th>article</th>\n",
       "      <th>full_response</th>\n",
       "      <th>explanation</th>\n",
       "      <th>title</th>\n",
       "      <th>is_adverse_media</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>630</td>\n",
       "      <td>631</td>\n",
       "      <td>729</td>\n",
       "      <td>729</td>\n",
       "      <td>729</td>\n",
       "      <td>633</td>\n",
       "      <td>729</td>\n",
       "      <td>729.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>483</td>\n",
       "      <td>16</td>\n",
       "      <td>729</td>\n",
       "      <td>729</td>\n",
       "      <td>729</td>\n",
       "      <td>370</td>\n",
       "      <td>723</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>John McAfee</td>\n",
       "      <td>individual</td>\n",
       "      <td>https://www.reuters.com/article/us-china-parli...</td>\n",
       "      <td>AUSTRAC has let Afterpay off the hook, conclud...</td>\n",
       "      <td>[{'query': {'id': '1605045416509-272a57a132609...</td>\n",
       "      <td>corruption</td>\n",
       "      <td>Top fund manager forced to resign after BBC in...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>8</td>\n",
       "      <td>185</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.563786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.496255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        entity_name entity_type  \\\n",
       "count           630         631   \n",
       "unique          483          16   \n",
       "top     John McAfee  individual   \n",
       "freq              8         185   \n",
       "mean            NaN         NaN   \n",
       "std             NaN         NaN   \n",
       "min             NaN         NaN   \n",
       "25%             NaN         NaN   \n",
       "50%             NaN         NaN   \n",
       "75%             NaN         NaN   \n",
       "max             NaN         NaN   \n",
       "\n",
       "                                                      url  \\\n",
       "count                                                 729   \n",
       "unique                                                729   \n",
       "top     https://www.reuters.com/article/us-china-parli...   \n",
       "freq                                                    1   \n",
       "mean                                                  NaN   \n",
       "std                                                   NaN   \n",
       "min                                                   NaN   \n",
       "25%                                                   NaN   \n",
       "50%                                                   NaN   \n",
       "75%                                                   NaN   \n",
       "max                                                   NaN   \n",
       "\n",
       "                                                  article  \\\n",
       "count                                                 729   \n",
       "unique                                                729   \n",
       "top     AUSTRAC has let Afterpay off the hook, conclud...   \n",
       "freq                                                    1   \n",
       "mean                                                  NaN   \n",
       "std                                                   NaN   \n",
       "min                                                   NaN   \n",
       "25%                                                   NaN   \n",
       "50%                                                   NaN   \n",
       "75%                                                   NaN   \n",
       "max                                                   NaN   \n",
       "\n",
       "                                            full_response explanation  \\\n",
       "count                                                 729         633   \n",
       "unique                                                729         370   \n",
       "top     [{'query': {'id': '1605045416509-272a57a132609...  corruption   \n",
       "freq                                                    1          34   \n",
       "mean                                                  NaN         NaN   \n",
       "std                                                   NaN         NaN   \n",
       "min                                                   NaN         NaN   \n",
       "25%                                                   NaN         NaN   \n",
       "50%                                                   NaN         NaN   \n",
       "75%                                                   NaN         NaN   \n",
       "max                                                   NaN         NaN   \n",
       "\n",
       "                                                    title  is_adverse_media  \n",
       "count                                                 729        729.000000  \n",
       "unique                                                723               NaN  \n",
       "top     Top fund manager forced to resign after BBC in...               NaN  \n",
       "freq                                                    2               NaN  \n",
       "mean                                                  NaN          0.563786  \n",
       "std                                                   NaN          0.496255  \n",
       "min                                                   NaN          0.000000  \n",
       "25%                                                   NaN          0.000000  \n",
       "50%                                                   NaN          1.000000  \n",
       "75%                                                   NaN          1.000000  \n",
       "max                                                   NaN          1.000000  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Keep only needed columns\n",
    "train = train.loc[:, ['entity_name', 'entity_type', 'url', 'article', 'full_response', 'explanation', 'title', 'is_adverse_media']]\n",
    "\n",
    "train.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can narrow our focus a little bit more... Let's check if there are any nulls in article & is_adverse_media columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(train.article.isna()), sum(train.is_adverse_media.isna())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We gotta do one last check before tokenizing the articles, we need to check if there are any non-english text managed to slip in during the data collection process. spaCy can do this with its langdetect module, hope you succeeded in installing it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install spacy-langdetect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'language': 'et', 'score': 0.9999954770273104}\n",
      "This is an english text. {'language': 'en', 'score': 0.9999967006441883}\n",
      "Ja see on eestikeelne lause. {'language': 'et', 'score': 0.9999955073916389}\n",
      "بوغيث\t {'language': 'ar', 'score': 0.9999971460100543}\n"
     ]
    }
   ],
   "source": [
    "# Make sure we only have English articles\n",
    "from spacy_langdetect import LanguageDetector\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "nlp.add_pipe(LanguageDetector(), name='language_detector', last=True)\n",
    "\n",
    "# Let's create an example doc object first to test spaCy's LanguageDetector.\n",
    "text = 'This is an english text. Ja see on eestikeelne lause. بوغيث\t'\n",
    "doc = nlp(text)\n",
    "# document level language detection. Think of it like average language of the document!\n",
    "print(doc._.language)\n",
    "# sentence level language detection\n",
    "for sent in doc.sents:\n",
    "    print(sent, sent._.language)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The language detector acts like a weirdo while trying to understand the average language of the document. Classifying the whole text as 85 percent Estonian is a bit too much in my opinion. Let's test it on an actual article in the train dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Bernie Madoff, who is scheduled to be sentenced June 29 for perpetrating history's biggest Ponzi scheme, is just be the latest in a long line of industry titans turned crooks\\n\\nCRIMINAL EXECUTIVE OFFICER\\nSam Waksal\\n\\nCEO:\\xa0ImClone\\nConvicted: October 15, 2002 of securities fraud, bank fraud, obstruction of justice, and perjury\\nKnown for his networking skills as much as for his scientific expertise, immunologist Sam Waksal founded ImClone in 1984. The New York-based biotech firm remained relatively unknown until 1999, when it announced the creation of Erbitux — a cancer-fighting drug so promising it convinced pharmaceutical giant Bristol-Myers to purchase $1 billion of ImClone stock in one of the largest biotechnology partnerships in U.S. history. But when the Food and Drug Administration rejected the drug, Waksal alerted several relatives and friends to dump their stock as soon as possible — before the FDA's decision had been made public. Waksal's father and daughter sold $9.2 million worth of ImClone, a move that caught the attention of the SEC and eventually led to his arrest.\\nThough Waksal pleaded guilty and publicly apologized to his family, his colleagues, and the millions of cancer patients who had held such high hopes for Erbitux, Judge William Pauley dismissed calls for leniency, noting that Waksal had contributed a mere one-half of 1 percent of his $133 million fortune to charity. In the end, the fallen entrepreneur paid $4.3 million in fines and tax restitution, and served 87 months in prison; he was released on Feb. 9, 2009. The scandal's most infamous casualty, however, turned out to be Waksal's pal, Martha Stewart, who had unloaded all 3,928 of her company shares just days before the FDA's decision had been announced to avoid losing an estimated $45,673; the domestic diva got five months in prison as a result.\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = train.article[8]\n",
    "example # Clearly this one's in English."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'language': 'en', 'score': 0.9999952401341312}\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(example)\n",
    "print(doc._.language)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With long texts like the articles we collected, spaCy does a good job.\n",
    "\n",
    "Now, let's check the whole dataset to see if any non-english article exists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['en', 'fr'], dtype=object)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['article'].apply(lambda article: nlp(article[:300])._.language['language']).unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of our articles are in English. We can now move on to creating tokens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before applying any vectorizer, we need to create tokens from our articles by cleaning them from punctuation, empty spaces etc. The helper function below will use some regex commands to handle all those, besides transforming all the letters to lowercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner']) \n",
    "\n",
    "# The regex below can be modified later on.\n",
    "def lemmatize(article):\n",
    "    article = re.sub(r'http\\S+', '', article)\n",
    "    article = re.sub(r\"#(\\w+)\", '', article)\n",
    "    article = re.sub(r\"@(\\w+)\", '', article)\n",
    "    article = re.sub(r'[^\\w\\s]', '', article)\n",
    "    article = re.sub(r'\\w*\\d\\w*','', article)\n",
    "    article = re.sub(' +',' ', article)\n",
    "    article = article.strip().lower()\n",
    "    \n",
    "    # Commenting this out - it is really not needed and very slow. No point in loading nlp again for EVERY article!\n",
    "    # nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner']) \n",
    "\n",
    "    doc = nlp(article)\n",
    "    lemmatized_article = \" \".join([token.lemma_ for token in doc if (token.is_stop==False)]) \n",
    "    \n",
    "    return lemmatized_article"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, let's use the lemmatize function on an example to see what it does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Lemmatization:\n",
      "\n",
      "Bernie Madoff, who is scheduled to be sentenced June 29 for perpetrating history's biggest Ponzi scheme, is just be the latest in a long line of industry titans turned crooks\n",
      "\n",
      "CRIMINAL EXECUTIVE OFFICER\n",
      "Sam Waksal\n",
      "\n",
      "CEO: ImClone\n",
      "Convicted: October 15, 2002 of securities fraud, bank fraud, obstruction of justice, and perjury\n",
      "Known for his networking skills as much as for his scientific expertise, immunologist Sam Waksal founded ImClone in 1984. The New York-based biotech firm remained relatively unknown until 1999, when it announced the creation of Erbitux — a cancer-fighting drug so promising it convinced pharmaceutical giant Bristol-Myers to purchase $1 billion of ImClone stock in one of the largest biotechnology partnerships in U.S. history. But when the Food and Drug Administration rejected the drug, Waksal alerted several relatives and friends to dump their stock as soon as possible — before the FDA's decision had been made public. Waksal's father and daughter sold $9.2 million worth of ImClone, a move that caught the attention of the SEC and eventually led to his arrest.\n",
      "Though Waksal pleaded guilty and publicly apologized to his family, his colleagues, and the millions of cancer patients who had held such high hopes for Erbitux, Judge William Pauley dismissed calls for leniency, noting that Waksal had contributed a mere one-half of 1 percent of his $133 million fortune to charity. In the end, the fallen entrepreneur paid $4.3 million in fines and tax restitution, and served 87 months in prison; he was released on Feb. 9, 2009. The scandal's most infamous casualty, however, turned out to be Waksal's pal, Martha Stewart, who had unloaded all 3,928 of her company shares just days before the FDA's decision had been announced to avoid losing an estimated $45,673; the domestic diva got five months in prison as a result.\n",
      "\n",
      "After Lemmatization:\n",
      "\n",
      "bernie madoff schedule sentence june perpetrate historys big ponzi scheme late long line industry titan turn crook \n",
      "\n",
      " criminal executive officer \n",
      " sam waksal \n",
      "\n",
      " ceo    imclone \n",
      " convict october securities fraud bank fraud obstruction justice perjury \n",
      " know networking skill scientific expertise immunologist sam waksal found imclone new yorkbase biotech firm remain relatively unknown announce creation erbitux cancerfighte drug promise convince pharmaceutical giant bristolmyer purchase billion imclone stock large biotechnology partnership history food drug administration reject drug waksal alert relative friend dump stock soon possible fdas decision public waksal father daughter sell million worth imclone catch attention sec eventually lead arrest \n",
      " waksal plead guilty publicly apologize family colleague million cancer patient hold high hope erbitux judge william pauley dismiss call leniency note waksal contribute mere onehalf percent million fortune charity end fall entrepreneur pay million fine tax restitution serve month prison release feb scandal infamous casualty turn waksal pal martha stewart unload company share day fdas decision announce avoid lose estimate domestic diva get month prison result\n",
      "\n"
     ]
    }
   ],
   "source": [
    "example = train.article[8]\n",
    "lemmatized = lemmatize(example)\n",
    "\n",
    "print('Before Lemmatization:')\n",
    "print()\n",
    "print(example)\n",
    "print()\n",
    "\n",
    "print('After Lemmatization:')\n",
    "print()\n",
    "print(lemmatized)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's copy our train data and apply lemmatization on the articles belonging to the copy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of our DataFrame: (729, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article</th>\n",
       "      <th>is_adverse_media</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bernie Madoff, who is scheduled to be sentence...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Published\\n\\nOne of the world's leading fund m...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Published\\n\\nThe founder of US futures broker ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WASHINGTON (AP) — An American security contrac...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A senior figure in the Bitcoin Foundation, whi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             article  is_adverse_media\n",
       "0  Bernie Madoff, who is scheduled to be sentence...                 1\n",
       "1  Published\\n\\nOne of the world's leading fund m...                 1\n",
       "2  Published\\n\\nThe founder of US futures broker ...                 1\n",
       "3  WASHINGTON (AP) — An American security contrac...                 1\n",
       "4  A senior figure in the Bitcoin Foundation, whi...                 1"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = train[['article', 'is_adverse_media']].copy()\n",
    "data = data.reset_index()\n",
    "data = data.drop(['index'], axis=1)\n",
    "print('Shape of our DataFrame:', data.shape)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article</th>\n",
       "      <th>is_adverse_media</th>\n",
       "      <th>lemmatized_articles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bernie Madoff, who is scheduled to be sentence...</td>\n",
       "      <td>1</td>\n",
       "      <td>bernie madoff schedule sentence june perpetrat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Published\\n\\nOne of the world's leading fund m...</td>\n",
       "      <td>1</td>\n",
       "      <td>publish \\n\\n world lead fund manager force res...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Published\\n\\nThe founder of US futures broker ...</td>\n",
       "      <td>1</td>\n",
       "      <td>publish \\n\\n founder future broker peregrine f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WASHINGTON (AP) — An American security contrac...</td>\n",
       "      <td>1</td>\n",
       "      <td>washington ap american security contractor acc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A senior figure in the Bitcoin Foundation, whi...</td>\n",
       "      <td>1</td>\n",
       "      <td>senior figure bitcoin foundation lobby behalf ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             article  is_adverse_media  \\\n",
       "0  Bernie Madoff, who is scheduled to be sentence...                 1   \n",
       "1  Published\\n\\nOne of the world's leading fund m...                 1   \n",
       "2  Published\\n\\nThe founder of US futures broker ...                 1   \n",
       "3  WASHINGTON (AP) — An American security contrac...                 1   \n",
       "4  A senior figure in the Bitcoin Foundation, whi...                 1   \n",
       "\n",
       "                                 lemmatized_articles  \n",
       "0  bernie madoff schedule sentence june perpetrat...  \n",
       "1  publish \\n\\n world lead fund manager force res...  \n",
       "2  publish \\n\\n founder future broker peregrine f...  \n",
       "3  washington ap american security contractor acc...  \n",
       "4  senior figure bitcoin foundation lobby behalf ...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['lemmatized_articles'] = data['article'].map(lemmatize)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of our DataFrame: (729, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_adverse_media</th>\n",
       "      <th>lemmatized_articles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>1</td>\n",
       "      <td>investment conman start prison sentence year w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>1</td>\n",
       "      <td>daja uncle accuse leader wellstructure crimina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>1</td>\n",
       "      <td>new york state file civil charge wednesday acc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>649</th>\n",
       "      <td>0</td>\n",
       "      <td>alex stamos rise fame chief security officer y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1</td>\n",
       "      <td>new york reuters honduran politician juan anto...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     is_adverse_media                                lemmatized_articles\n",
       "263                 1  investment conman start prison sentence year w...\n",
       "316                 1  daja uncle accuse leader wellstructure crimina...\n",
       "210                 1  new york state file civil charge wednesday acc...\n",
       "649                 0  alex stamos rise fame chief security officer y...\n",
       "32                  1  new york reuters honduran politician juan anto..."
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data[['is_adverse_media', 'lemmatized_articles']] # These are the only columns that we need for modeling\n",
    "data = data.sample(frac = 1) # Let us not forget to shuffle the rows before train_test_split\n",
    "\n",
    "print('Shape of our DataFrame:', data.shape)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(656,) (73,) (656,) (73,)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(data['lemmatized_articles'], \n",
    "                                                    data['is_adverse_media'], \n",
    "                                                    test_size=0.1, \n",
    "                                                    random_state=42,\n",
    "                                                    stratify=data['is_adverse_media'])\n",
    "\n",
    "print(x_train.shape, x_val.shape, y_train.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "297    north korean hacker steal million cryptocurren...\n",
       "280    brazils attorney general charge president mich...\n",
       "649    alex stamos rise fame chief security officer y...\n",
       "83     seven individual charge indictment district so...\n",
       "104    image copyrightafp \\n\\n hollywood producer riz...\n",
       "Name: lemmatized_articles, dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF on Train Data and Baseline Logistic Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The train and validation sets are ready for applying a vectorizer function. Instead of creating the document-term matrix by simply counting the number of occurrences of words(ie bag of words approach), I will apply a tf-idf vectorizer on train data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer(max_df=0.5, max_features=40000, min_df=5, ngram_range=(1, 3),\n",
      "                stop_words='english')\n"
     ]
    }
   ],
   "source": [
    "ngram_vectorizer = TfidfVectorizer(max_features=40000,\n",
    "                             min_df=5, \n",
    "                             max_df=0.5, \n",
    "                             analyzer='word', \n",
    "                             stop_words='english', \n",
    "                             ngram_range=(1, 3))\n",
    "print(ngram_vectorizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's fit the vectorizer to x_train and take a look at the feature names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['turkish',\n",
       " 'drug sale',\n",
       " 'confirm',\n",
       " 'alqaida',\n",
       " 'invasion',\n",
       " 'unlicensed money transmit',\n",
       " 'netherlands',\n",
       " 'willful',\n",
       " 'population',\n",
       " 'new product',\n",
       " 'destruction',\n",
       " 'mcafee arrest',\n",
       " 'affidavit',\n",
       " 'legal action',\n",
       " 'states attorneys',\n",
       " 'declaration',\n",
       " 'municipal',\n",
       " 'police chief',\n",
       " 'mismanagement',\n",
       " 'security fraud']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "ngram_vectorizer.fit(x_train)\n",
    "features = ngram_vectorizer.get_feature_names()\n",
    "\n",
    "random.sample(features, k=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_train = ngram_vectorizer.transform(x_train)\n",
    "tfidf_validation = ngram_vectorizer.transform(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.       , 0.       , 0.       , ..., 0.       , 0.       ,\n",
       "        0.       ],\n",
       "       [0.       , 0.       , 0.       , ..., 0.       , 0.       ,\n",
       "        0.       ],\n",
       "       [0.       , 0.       , 0.       , ..., 0.       , 0.       ,\n",
       "        0.       ],\n",
       "       ...,\n",
       "       [0.       , 0.       , 0.       , ..., 0.       , 0.       ,\n",
       "        0.       ],\n",
       "       [0.       , 0.       , 0.       , ..., 0.       , 0.       ,\n",
       "        0.       ],\n",
       "       [0.0367679, 0.       , 0.       , ..., 0.       , 0.       ,\n",
       "        0.       ]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_array = tfidf_train.toarray()\n",
    "doc_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abandon</th>\n",
       "      <th>abdul</th>\n",
       "      <th>abdullah</th>\n",
       "      <th>abide</th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>abroad</th>\n",
       "      <th>absence</th>\n",
       "      <th>absolute</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>...</th>\n",
       "      <th>zayed</th>\n",
       "      <th>zero</th>\n",
       "      <th>zero tolerance</th>\n",
       "      <th>zetas</th>\n",
       "      <th>zimbabwe</th>\n",
       "      <th>zimbabwe anticorruption</th>\n",
       "      <th>zimbabwe anticorruption commission</th>\n",
       "      <th>zimbabwean</th>\n",
       "      <th>zimbabwes</th>\n",
       "      <th>zone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.032907</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.062204</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 6509 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   abandon  abdul  abdullah  abide   ability      able  abroad  absence  \\\n",
       "0      0.0    0.0       0.0    0.0  0.000000  0.000000     0.0      0.0   \n",
       "1      0.0    0.0       0.0    0.0  0.000000  0.032907     0.0      0.0   \n",
       "2      0.0    0.0       0.0    0.0  0.000000  0.000000     0.0      0.0   \n",
       "3      0.0    0.0       0.0    0.0  0.000000  0.000000     0.0      0.0   \n",
       "4      0.0    0.0       0.0    0.0  0.000000  0.000000     0.0      0.0   \n",
       "5      0.0    0.0       0.0    0.0  0.000000  0.000000     0.0      0.0   \n",
       "6      0.0    0.0       0.0    0.0  0.000000  0.000000     0.0      0.0   \n",
       "7      0.0    0.0       0.0    0.0  0.062204  0.000000     0.0      0.0   \n",
       "8      0.0    0.0       0.0    0.0  0.000000  0.000000     0.0      0.0   \n",
       "9      0.0    0.0       0.0    0.0  0.000000  0.000000     0.0      0.0   \n",
       "\n",
       "   absolute  absolutely  ...  zayed  zero  zero tolerance  zetas  zimbabwe  \\\n",
       "0       0.0         0.0  ...    0.0   0.0             0.0    0.0       0.0   \n",
       "1       0.0         0.0  ...    0.0   0.0             0.0    0.0       0.0   \n",
       "2       0.0         0.0  ...    0.0   0.0             0.0    0.0       0.0   \n",
       "3       0.0         0.0  ...    0.0   0.0             0.0    0.0       0.0   \n",
       "4       0.0         0.0  ...    0.0   0.0             0.0    0.0       0.0   \n",
       "5       0.0         0.0  ...    0.0   0.0             0.0    0.0       0.0   \n",
       "6       0.0         0.0  ...    0.0   0.0             0.0    0.0       0.0   \n",
       "7       0.0         0.0  ...    0.0   0.0             0.0    0.0       0.0   \n",
       "8       0.0         0.0  ...    0.0   0.0             0.0    0.0       0.0   \n",
       "9       0.0         0.0  ...    0.0   0.0             0.0    0.0       0.0   \n",
       "\n",
       "   zimbabwe anticorruption  zimbabwe anticorruption commission  zimbabwean  \\\n",
       "0                      0.0                                 0.0         0.0   \n",
       "1                      0.0                                 0.0         0.0   \n",
       "2                      0.0                                 0.0         0.0   \n",
       "3                      0.0                                 0.0         0.0   \n",
       "4                      0.0                                 0.0         0.0   \n",
       "5                      0.0                                 0.0         0.0   \n",
       "6                      0.0                                 0.0         0.0   \n",
       "7                      0.0                                 0.0         0.0   \n",
       "8                      0.0                                 0.0         0.0   \n",
       "9                      0.0                                 0.0         0.0   \n",
       "\n",
       "   zimbabwes  zone  \n",
       "0        0.0   0.0  \n",
       "1        0.0   0.0  \n",
       "2        0.0   0.0  \n",
       "3        0.0   0.0  \n",
       "4        0.0   0.0  \n",
       "5        0.0   0.0  \n",
       "6        0.0   0.0  \n",
       "7        0.0   0.0  \n",
       "8        0.0   0.0  \n",
       "9        0.0   0.0  \n",
       "\n",
       "[10 rows x 6509 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequency_matrix = pd.DataFrame(doc_array, \n",
    "                                columns = features)\n",
    "frequency_matrix.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both the train and the validation datasets are transformed. Now we need to fit a  basic logistic regression model to see how far it can get with f1 score and accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(solver='sag')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(solver='sag')\n",
    "lr.fit(tfidf_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds_lr = lr.predict(tfidf_train)\n",
    "val_preds_lr = lr.predict(tfidf_validation)\n",
    "\n",
    "train_f1_score_lr = f1_score(y_train, train_preds_lr)\n",
    "val_f1_score_lr = f1_score(y_val, val_preds_lr)\n",
    "\n",
    "train_accuracy_lr = accuracy_score(y_train, train_preds_lr)\n",
    "val_accuracy_lr = accuracy_score(y_val, val_preds_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction accuracy for logistic regression model on train data: 96.189\n",
      "Prediction accuracy for logistic regression model on validation data: 87.671\n",
      "\n",
      "F1 score for logistic regression model on train data: 96.697\n",
      "F1 score for logistic regression model on validation data: 89.655\n"
     ]
    }
   ],
   "source": [
    "print('Prediction accuracy for logistic regression model on train data:', round(train_accuracy_lr*100, 3))\n",
    "print('Prediction accuracy for logistic regression model on validation data:', round(val_accuracy_lr*100, 3))\n",
    "\n",
    "print()\n",
    "\n",
    "print('F1 score for logistic regression model on train data:', round(train_f1_score_lr*100, 3))\n",
    "print('F1 score for logistic regression model on validation data:', round(val_f1_score_lr*100, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results seem good, but they can get better, in test data we will most probably see some overfitting. **Yet, for now, I am skipping the regularization part, since I would like to see the results on public test data before doing any serious regularization & tuning.**\n",
    "\n",
    "Let's get to the naive bayes part and let's see if it can beat the validation f1 score put forward by the logistic regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second Baseline Model: Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike what I have done above, I will provide some helper functions for tuning the Naive Bayes model here, since it requires only one parameter, alpha, to tune.\n",
    "\n",
    "Hopefully Naive Bayes will result in a high f1 score as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "\n",
    "def get_auc_CV(model):\n",
    "    \"\"\"\n",
    "    Return the average AUC score from cross-validation.\n",
    "    \"\"\"\n",
    "    # Set KFold to shuffle data before the split\n",
    "    kf = StratifiedKFold(5, shuffle=True, random_state=1)\n",
    "\n",
    "    # Get AUC scores\n",
    "    auc = cross_val_score(model, tfidf_train, y_train, scoring=\"roc_auc\", cv=kf)\n",
    "\n",
    "    return auc.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will check the AUC scores and see what smoothing parameter works the best for lutinomial naive bayes. It may look weird that we have used cross validation above even though we have a validation dataset already, but think of the latter as the public test for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha:  0.1\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "res = pd.Series([get_auc_CV(MultinomialNB(alpha = i))\n",
    "                 for i in np.arange(0.1, 10, 0.1)],\n",
    "                index=np.arange(0.1, 10, 0.1))\n",
    "\n",
    "best_alpha = np.round(res.idxmax(), 2)\n",
    "print('Best alpha: ', best_alpha)\n",
    "\n",
    "plt.plot(res)\n",
    "plt.title('AUC vs. Alpha')\n",
    "plt.xlabel('Alpha')\n",
    "plt.ylabel('AUC')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_curve, auc\n",
    "\n",
    "def evaluate_roc(probs, y_true):\n",
    "    \"\"\"\n",
    "    - Print AUC and accuracy on the test set\n",
    "    - Plot ROC\n",
    "    @params    probs (np.array): an array of predicted probabilities with shape (len(y_true), 2)\n",
    "    @params    y_true (np.array): an array of the true values with shape (len(y_true),)\n",
    "    \"\"\"\n",
    "    preds = probs[:, 1]\n",
    "    fpr, tpr, threshold = roc_curve(y_true, preds)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    print(f'AUC: {roc_auc:.4f}')\n",
    "       \n",
    "    # Get accuracy over the test set\n",
    "    y_pred = np.where(preds >= 0.5, 1, 0)\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    print(f'Accuracy: {accuracy*100:.2f}%')\n",
    "    \n",
    "    # Plot ROC AUC\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.plot([0, 1], [0, 1],'r--')\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.9520\n",
      "Accuracy: 90.41%\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compute predicted probabilities\n",
    "nb_model = MultinomialNB(alpha=best_alpha)\n",
    "nb_model.fit(tfidf_train, y_train)\n",
    "probs = nb_model.predict_proba(tfidf_validation)\n",
    "\n",
    "# Evaluate the classifier\n",
    "evaluate_roc(probs, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds_nb = nb_model.predict(tfidf_train)\n",
    "val_preds_nb = nb_model.predict(tfidf_validation)\n",
    "\n",
    "train_f1_score_nb = f1_score(y_train, train_preds_nb)\n",
    "val_f1_score_nb = f1_score(y_val, val_preds_nb)\n",
    "\n",
    "train_accuracy_nb = accuracy_score(y_train, train_preds_nb)\n",
    "val_accuracy_nb = accuracy_score(y_val, val_preds_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction accuracy for naive bayes model on train data: 96.799\n",
      "Prediction accuracy for naive bayes model on validation data: 90.411\n",
      "\n",
      "F1 score for naive bayes model on train data: 97.158\n",
      "F1 score for naive bayes model on validation data: 91.358\n"
     ]
    }
   ],
   "source": [
    "print('Prediction accuracy for naive bayes model on train data:', round(train_accuracy_nb*100, 3))\n",
    "print('Prediction accuracy for naive bayes model on validation data:', round(val_accuracy_nb*100, 3))\n",
    "\n",
    "print()\n",
    "\n",
    "print('F1 score for naive bayes model on train data:', round(train_f1_score_nb*100, 3))\n",
    "print('F1 score for naive bayes model on validation data:', round(val_f1_score_nb*100, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive bayes performed very similar, yet worse than logistic regression, the latter had an f1 score of 0.889.\n",
    "\n",
    "To get an understanding of what algorithm fares better, we still need to test both of them on public test.\n",
    "\n",
    "It's time to try out a crude LSTM model on our data now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TESTING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('../../public_test.csv')\n",
    "x_test = test_df['article'].map(lemmatize)\n",
    "tfidf_test = ngram_vectorizer.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test with Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.916256157635468"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "test_preds_lr = lr.predict(tfidf_test)\n",
    "y_test = test_df['label']\n",
    "f1_score(y_test, test_preds_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test with Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9238578680203046"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_preds_nb = nb_model.predict(tfidf_test)\n",
    "f1_score(y_test, test_preds_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
