{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.6"
    },
    "colab": {
      "name": "LSTM without Glove_Untuned .ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "8pH4B-eFUD1Q"
      },
      "source": [
        "import warnings\n",
        "warnings.simplefilter(\"ignore\", UserWarning)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OdvE8iJbUD1R"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import spacy\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# For regular expressions\n",
        "import re\n",
        "\n",
        "# For handling strings\n",
        "import string\n",
        "\n",
        "# For performing mathematical operations\n",
        "import math\n",
        "\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
        "from sklearn.metrics import accuracy_score, auc, roc_auc_score, roc_curve, f1_score, confusion_matrix\n",
        "from keras import backend as K\n",
        "\n",
        "# This module will be for saving the trained model for later use\n",
        "import joblib"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ywRZ258CUD1S"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.text import text_to_word_sequence\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "from keras.models import Model\n",
        "from keras.models import Sequential\n",
        "\n",
        "from keras.layers import Input, Dense, Embedding, Conv1D, Conv2D, MaxPooling1D, MaxPool2D\n",
        "from keras.layers import Reshape, Flatten, Dropout, Concatenate\n",
        "from keras.layers import SpatialDropout1D, concatenate\n",
        "from keras.layers import LSTM, Bidirectional, GlobalAveragePooling1D, GlobalMaxPooling1D\n",
        "\n",
        "from keras.callbacks import Callback\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from keras.models import load_model\n",
        "from keras.utils.vis_utils import plot_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VUDOKRTzUD1S"
      },
      "source": [
        "from tqdm import tqdm_notebook"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "bLpLP2ZmUD1S",
        "outputId": "5730736d-a8ec-4ea2-ba19-b25ca6ea2ae3"
      },
      "source": [
        "df = pd.read_csv('cleaned_lemmatized_text.csv')\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>is_adverse_media</th>\n",
              "      <th>lemmatized_articles</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>zimbabweans wake news agriculture minister per...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>singapore founder singapore oil trade company ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>fraudster offer green tax efficient investment...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>buenos aire reuter judicial probe possible cor...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>ukraines constitutional court appear strike bl...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   is_adverse_media                                lemmatized_articles\n",
              "0                 0  zimbabweans wake news agriculture minister per...\n",
              "1                 1  singapore founder singapore oil trade company ...\n",
              "2                 1  fraudster offer green tax efficient investment...\n",
              "3                 1  buenos aire reuter judicial probe possible cor...\n",
              "4                 0  ukraines constitutional court appear strike bl..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wb4-xTzXUD1T",
        "outputId": "d4f40c7a-101f-4519-8036-86575c18a6b2"
      },
      "source": [
        "x_train, x_val, y_train, y_val = train_test_split(df['lemmatized_articles'], \n",
        "                                                    df['is_adverse_media'], \n",
        "                                                    test_size=0.1, \n",
        "                                                    random_state=42,\n",
        "                                                    stratify=df['is_adverse_media'])\n",
        "\n",
        "print(x_train.shape, x_val.shape, y_train.shape, y_val.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(656,) (73,) (656,) (73,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tuo3-Q1cUD1U",
        "outputId": "69467252-ba09-4174-b2fb-35ae5d5eff9e"
      },
      "source": [
        "MAX_NB_WORDS = 80000\n",
        "oov_token = '<UNK>'\n",
        "pad_type = 'post'\n",
        "trunc_type = 'post'\n",
        "\n",
        "tokenizer = Tokenizer(num_words=MAX_NB_WORDS, oov_token=oov_token)\n",
        "tokenizer.fit_on_texts(x_train)\n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "# Encode training data sentences into sequences\n",
        "train_sequences = tokenizer.texts_to_sequences(x_train)\n",
        "\n",
        "# Get max training sequence length\n",
        "maxlen = 600\n",
        "\n",
        "# Pad the training sequences\n",
        "train_padded = pad_sequences(train_sequences, padding=pad_type, truncating=trunc_type, maxlen=maxlen)\n",
        "\n",
        "# Output the results of our work\n",
        "#print(\"Word index:\\n\", word_index)\n",
        "#print(\"\\nTraining sequences:\\n\", train_sequences)\n",
        "print(\"\\nPadded training sequences:\\n\", train_padded)\n",
        "print(\"\\nPadded training shape:\", train_padded.shape)\n",
        "print(\"Training sequences data type:\", type(train_sequences))\n",
        "print(\"Padded Training sequences data type:\", type(train_padded))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Padded training sequences:\n",
            " [[ 197  342 3000 ... 1629  190 5034]\n",
            " [2733  164  141 ...    0    0    0]\n",
            " [9229 2865  281 ...    0    0    0]\n",
            " ...\n",
            " [ 701   42  475 ...    0    0    0]\n",
            " [5330 3876  556 ...    0    0    0]\n",
            " [ 197 1244 2584 ...    0    0    0]]\n",
            "\n",
            "Padded training shape: (656, 600)\n",
            "Training sequences data type: <class 'list'>\n",
            "Padded Training sequences data type: <class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NhrrKWMPUD1U",
        "outputId": "91994db5-33f6-4b15-8633-618479d2b989"
      },
      "source": [
        "val_sequences = tokenizer.texts_to_sequences(x_val)\n",
        "val_padded = pad_sequences(val_sequences, padding=pad_type, truncating=trunc_type, maxlen=maxlen)\n",
        "\n",
        "#print(\"Val sequences:\\n\", val_sequences)\n",
        "#print(\"\\nPadded val sequences:\\n\", val_padded)\n",
        "print(\"\\nPadded val shape:\",val_padded.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Padded val shape: (73, 600)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQW58AiymxjC"
      },
      "source": [
        "def recall_m(y_true, y_pred):\r\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\r\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\r\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\r\n",
        "    return recall\r\n",
        "\r\n",
        "def precision_m(y_true, y_pred):\r\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\r\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\r\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\r\n",
        "    return precision\r\n",
        "\r\n",
        "def f1_m(y_true, y_pred):\r\n",
        "    precision = precision_m(y_true, y_pred)\r\n",
        "    recall = recall_m(y_true, y_pred)\r\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99m9l-ESUD1V"
      },
      "source": [
        "def get_simple_rnn_model():\n",
        "    embedding_dim = 300\n",
        "    embedding_matrix = np.random.random((MAX_NB_WORDS, embedding_dim))\n",
        "    \n",
        "    inp = Input(shape=(maxlen, ))\n",
        "    x = Embedding(input_dim=MAX_NB_WORDS, output_dim=embedding_dim, input_length=maxlen, \n",
        "                  weights=[embedding_matrix], trainable=True)(inp)\n",
        "    x = SpatialDropout1D(0.3)(x)\n",
        "    x = Bidirectional(LSTM(100, return_sequences=True))(x)\n",
        "    avg_pool = GlobalAveragePooling1D()(x)\n",
        "    max_pool = GlobalMaxPooling1D()(x)\n",
        "    conc = concatenate([avg_pool, max_pool])\n",
        "    outp = Dense(1, activation=\"sigmoid\")(conc)\n",
        "    \n",
        "    model = Model(inputs=inp, outputs=outp)\n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy', f1_m])\n",
        "    return model\n",
        "\n",
        "rnn_simple_model = get_simple_rnn_model()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jAF_-e97UD1W",
        "outputId": "d77eb521-a643-4c95-9307-4264e606be0c"
      },
      "source": [
        "filepath=\"weights-improvement-{epoch:02d}-{val_f1_m:.4f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_f1_m', verbose=1, save_best_only=True, mode='max')\n",
        "\n",
        "batch_size = 128\n",
        "epochs = 40\n",
        "\n",
        "history = rnn_simple_model.fit(x=train_padded, \n",
        "                    y=y_train, \n",
        "                    validation_data=(val_padded, y_val), \n",
        "                    batch_size=batch_size, \n",
        "                    callbacks=[checkpoint], \n",
        "                    epochs=epochs, \n",
        "                    verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.7911 - accuracy: 0.5259 - f1_m: 0.4687\n",
            "Epoch 00001: val_f1_m improved from -inf to 0.00000, saving model to weights-improvement-01-0.0000.hdf5\n",
            "6/6 [==============================] - 3s 552ms/step - loss: 0.7911 - accuracy: 0.5259 - f1_m: 0.4687 - val_loss: 0.7998 - val_accuracy: 0.4384 - val_f1_m: 0.0000e+00\n",
            "Epoch 2/40\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.7191 - accuracy: 0.4924 - f1_m: 0.4248\n",
            "Epoch 00002: val_f1_m improved from 0.00000 to 0.71930, saving model to weights-improvement-02-0.7193.hdf5\n",
            "6/6 [==============================] - 3s 443ms/step - loss: 0.7191 - accuracy: 0.4924 - f1_m: 0.4248 - val_loss: 0.7439 - val_accuracy: 0.5616 - val_f1_m: 0.7193\n",
            "Epoch 3/40\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.7125 - accuracy: 0.5640 - f1_m: 0.7035\n",
            "Epoch 00003: val_f1_m improved from 0.71930 to 0.74074, saving model to weights-improvement-03-0.7407.hdf5\n",
            "6/6 [==============================] - 2s 404ms/step - loss: 0.7125 - accuracy: 0.5640 - f1_m: 0.7035 - val_loss: 0.6812 - val_accuracy: 0.6164 - val_f1_m: 0.7407\n",
            "Epoch 4/40\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.6930 - accuracy: 0.5076 - f1_m: 0.2621\n",
            "Epoch 00004: val_f1_m did not improve from 0.74074\n",
            "6/6 [==============================] - 2s 281ms/step - loss: 0.6930 - accuracy: 0.5076 - f1_m: 0.2621 - val_loss: 0.6880 - val_accuracy: 0.4932 - val_f1_m: 0.2449\n",
            "Epoch 5/40\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.6803 - accuracy: 0.5655 - f1_m: 0.6003\n",
            "Epoch 00005: val_f1_m did not improve from 0.74074\n",
            "6/6 [==============================] - 2s 289ms/step - loss: 0.6803 - accuracy: 0.5655 - f1_m: 0.6003 - val_loss: 0.6725 - val_accuracy: 0.5616 - val_f1_m: 0.7193\n",
            "Epoch 6/40\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.6715 - accuracy: 0.5747 - f1_m: 0.7351\n",
            "Epoch 00006: val_f1_m did not improve from 0.74074\n",
            "6/6 [==============================] - 2s 278ms/step - loss: 0.6715 - accuracy: 0.5747 - f1_m: 0.7351 - val_loss: 0.6666 - val_accuracy: 0.5616 - val_f1_m: 0.7193\n",
            "Epoch 7/40\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.6686 - accuracy: 0.5686 - f1_m: 0.7402\n",
            "Epoch 00007: val_f1_m did not improve from 0.74074\n",
            "6/6 [==============================] - 2s 284ms/step - loss: 0.6686 - accuracy: 0.5686 - f1_m: 0.7402 - val_loss: 0.6680 - val_accuracy: 0.5616 - val_f1_m: 0.7193\n",
            "Epoch 8/40\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.6678 - accuracy: 0.5671 - f1_m: 0.7329\n",
            "Epoch 00008: val_f1_m did not improve from 0.74074\n",
            "6/6 [==============================] - 2s 282ms/step - loss: 0.6678 - accuracy: 0.5671 - f1_m: 0.7329 - val_loss: 0.6577 - val_accuracy: 0.5616 - val_f1_m: 0.7193\n",
            "Epoch 9/40\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.6571 - accuracy: 0.5899 - f1_m: 0.7083\n",
            "Epoch 00009: val_f1_m improved from 0.74074 to 0.76471, saving model to weights-improvement-09-0.7647.hdf5\n",
            "6/6 [==============================] - 2s 404ms/step - loss: 0.6571 - accuracy: 0.5899 - f1_m: 0.7083 - val_loss: 0.6500 - val_accuracy: 0.6712 - val_f1_m: 0.7647\n",
            "Epoch 10/40\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.6529 - accuracy: 0.6905 - f1_m: 0.7357\n",
            "Epoch 00010: val_f1_m improved from 0.76471 to 0.79612, saving model to weights-improvement-10-0.7961.hdf5\n",
            "6/6 [==============================] - 2s 412ms/step - loss: 0.6529 - accuracy: 0.6905 - f1_m: 0.7357 - val_loss: 0.6413 - val_accuracy: 0.7123 - val_f1_m: 0.7961\n",
            "Epoch 11/40\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.6403 - accuracy: 0.6829 - f1_m: 0.7768\n",
            "Epoch 00011: val_f1_m did not improve from 0.79612\n",
            "6/6 [==============================] - 2s 278ms/step - loss: 0.6403 - accuracy: 0.6829 - f1_m: 0.7768 - val_loss: 0.6347 - val_accuracy: 0.5616 - val_f1_m: 0.7193\n",
            "Epoch 12/40\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.6270 - accuracy: 0.5762 - f1_m: 0.7386\n",
            "Epoch 00012: val_f1_m did not improve from 0.79612\n",
            "6/6 [==============================] - 2s 286ms/step - loss: 0.6270 - accuracy: 0.5762 - f1_m: 0.7386 - val_loss: 0.6169 - val_accuracy: 0.6438 - val_f1_m: 0.7593\n",
            "Epoch 13/40\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.6078 - accuracy: 0.7088 - f1_m: 0.8064\n",
            "Epoch 00013: val_f1_m did not improve from 0.79612\n",
            "6/6 [==============================] - 2s 280ms/step - loss: 0.6078 - accuracy: 0.7088 - f1_m: 0.8064 - val_loss: 0.6005 - val_accuracy: 0.6849 - val_f1_m: 0.7810\n",
            "Epoch 14/40\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.5895 - accuracy: 0.7652 - f1_m: 0.8187\n",
            "Epoch 00014: val_f1_m improved from 0.79612 to 0.82105, saving model to weights-improvement-14-0.8211.hdf5\n",
            "6/6 [==============================] - 2s 404ms/step - loss: 0.5895 - accuracy: 0.7652 - f1_m: 0.8187 - val_loss: 0.5794 - val_accuracy: 0.7671 - val_f1_m: 0.8211\n",
            "Epoch 15/40\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.5678 - accuracy: 0.8110 - f1_m: 0.8522\n",
            "Epoch 00015: val_f1_m improved from 0.82105 to 0.84444, saving model to weights-improvement-15-0.8444.hdf5\n",
            "6/6 [==============================] - 3s 424ms/step - loss: 0.5678 - accuracy: 0.8110 - f1_m: 0.8522 - val_loss: 0.5580 - val_accuracy: 0.8082 - val_f1_m: 0.8444\n",
            "Epoch 16/40\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.5451 - accuracy: 0.8186 - f1_m: 0.8505\n",
            "Epoch 00016: val_f1_m improved from 0.84444 to 0.85393, saving model to weights-improvement-16-0.8539.hdf5\n",
            "6/6 [==============================] - 3s 425ms/step - loss: 0.5451 - accuracy: 0.8186 - f1_m: 0.8505 - val_loss: 0.5376 - val_accuracy: 0.8219 - val_f1_m: 0.8539\n",
            "Epoch 17/40\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.5151 - accuracy: 0.8582 - f1_m: 0.8751\n",
            "Epoch 00017: val_f1_m did not improve from 0.85393\n",
            "6/6 [==============================] - 2s 296ms/step - loss: 0.5151 - accuracy: 0.8582 - f1_m: 0.8751 - val_loss: 0.5168 - val_accuracy: 0.8219 - val_f1_m: 0.8539\n",
            "Epoch 18/40\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.4860 - accuracy: 0.8704 - f1_m: 0.8986\n",
            "Epoch 00018: val_f1_m improved from 0.85393 to 0.86364, saving model to weights-improvement-18-0.8636.hdf5\n",
            "6/6 [==============================] - 3s 431ms/step - loss: 0.4860 - accuracy: 0.8704 - f1_m: 0.8986 - val_loss: 0.4992 - val_accuracy: 0.8356 - val_f1_m: 0.8636\n",
            "Epoch 19/40\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.4612 - accuracy: 0.8674 - f1_m: 0.8866\n",
            "Epoch 00019: val_f1_m did not improve from 0.86364\n",
            "6/6 [==============================] - 2s 297ms/step - loss: 0.4612 - accuracy: 0.8674 - f1_m: 0.8866 - val_loss: 0.4791 - val_accuracy: 0.8219 - val_f1_m: 0.8539\n",
            "Epoch 20/40\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.4344 - accuracy: 0.8948 - f1_m: 0.9201\n",
            "Epoch 00020: val_f1_m did not improve from 0.86364\n",
            "6/6 [==============================] - 2s 293ms/step - loss: 0.4344 - accuracy: 0.8948 - f1_m: 0.9201 - val_loss: 0.4717 - val_accuracy: 0.8082 - val_f1_m: 0.8511\n",
            "Epoch 21/40\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.4167 - accuracy: 0.8902 - f1_m: 0.8982\n",
            "Epoch 00021: val_f1_m did not improve from 0.86364\n",
            "6/6 [==============================] - 2s 288ms/step - loss: 0.4167 - accuracy: 0.8902 - f1_m: 0.8982 - val_loss: 0.4433 - val_accuracy: 0.8219 - val_f1_m: 0.8471\n",
            "Epoch 22/40\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.3750 - accuracy: 0.8994 - f1_m: 0.9206\n",
            "Epoch 00022: val_f1_m did not improve from 0.86364\n",
            "6/6 [==============================] - 2s 293ms/step - loss: 0.3750 - accuracy: 0.8994 - f1_m: 0.9206 - val_loss: 0.4526 - val_accuracy: 0.8082 - val_f1_m: 0.8511\n",
            "Epoch 23/40\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.3565 - accuracy: 0.8994 - f1_m: 0.9148\n",
            "Epoch 00023: val_f1_m did not improve from 0.86364\n",
            "6/6 [==============================] - 2s 288ms/step - loss: 0.3565 - accuracy: 0.8994 - f1_m: 0.9148 - val_loss: 0.4349 - val_accuracy: 0.8219 - val_f1_m: 0.8267\n",
            "Epoch 24/40\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.3470 - accuracy: 0.8979 - f1_m: 0.8948\n",
            "Epoch 00024: val_f1_m improved from 0.86364 to 0.86957, saving model to weights-improvement-24-0.8696.hdf5\n",
            "6/6 [==============================] - 3s 428ms/step - loss: 0.3470 - accuracy: 0.8979 - f1_m: 0.8948 - val_loss: 0.4193 - val_accuracy: 0.8356 - val_f1_m: 0.8696\n",
            "Epoch 25/40\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.3169 - accuracy: 0.9116 - f1_m: 0.9225\n",
            "Epoch 00025: val_f1_m did not improve from 0.86957\n",
            "6/6 [==============================] - 2s 292ms/step - loss: 0.3169 - accuracy: 0.9116 - f1_m: 0.9225 - val_loss: 0.3947 - val_accuracy: 0.8219 - val_f1_m: 0.8471\n",
            "Epoch 26/40\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.2851 - accuracy: 0.9329 - f1_m: 0.9498\n",
            "Epoch 00026: val_f1_m did not improve from 0.86957\n",
            "6/6 [==============================] - 2s 288ms/step - loss: 0.2851 - accuracy: 0.9329 - f1_m: 0.9498 - val_loss: 0.3858 - val_accuracy: 0.8493 - val_f1_m: 0.8675\n",
            "Epoch 27/40\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.2736 - accuracy: 0.9360 - f1_m: 0.9297\n",
            "Epoch 00027: val_f1_m did not improve from 0.86957\n",
            "6/6 [==============================] - 2s 294ms/step - loss: 0.2736 - accuracy: 0.9360 - f1_m: 0.9297 - val_loss: 0.3845 - val_accuracy: 0.8356 - val_f1_m: 0.8462\n",
            "Epoch 28/40\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.2642 - accuracy: 0.9345 - f1_m: 0.9400\n",
            "Epoch 00028: val_f1_m did not improve from 0.86957\n",
            "6/6 [==============================] - 2s 290ms/step - loss: 0.2642 - accuracy: 0.9345 - f1_m: 0.9400 - val_loss: 0.4159 - val_accuracy: 0.8219 - val_f1_m: 0.8602\n",
            "Epoch 29/40\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.2483 - accuracy: 0.9375 - f1_m: 0.9412\n",
            "Epoch 00029: val_f1_m did not improve from 0.86957\n",
            "6/6 [==============================] - 2s 293ms/step - loss: 0.2483 - accuracy: 0.9375 - f1_m: 0.9412 - val_loss: 0.3750 - val_accuracy: 0.8356 - val_f1_m: 0.8462\n",
            "Epoch 30/40\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.2325 - accuracy: 0.9482 - f1_m: 0.9608\n",
            "Epoch 00030: val_f1_m did not improve from 0.86957\n",
            "6/6 [==============================] - 2s 291ms/step - loss: 0.2325 - accuracy: 0.9482 - f1_m: 0.9608 - val_loss: 0.3695 - val_accuracy: 0.8356 - val_f1_m: 0.8636\n",
            "Epoch 31/40\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.1998 - accuracy: 0.9649 - f1_m: 0.9628\n",
            "Epoch 00031: val_f1_m improved from 0.86957 to 0.89157, saving model to weights-improvement-31-0.8916.hdf5\n",
            "6/6 [==============================] - 3s 417ms/step - loss: 0.1998 - accuracy: 0.9649 - f1_m: 0.9628 - val_loss: 0.3536 - val_accuracy: 0.8767 - val_f1_m: 0.8916\n",
            "Epoch 32/40\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.1853 - accuracy: 0.9649 - f1_m: 0.9736\n",
            "Epoch 00032: val_f1_m did not improve from 0.89157\n",
            "6/6 [==============================] - 2s 300ms/step - loss: 0.1853 - accuracy: 0.9649 - f1_m: 0.9736 - val_loss: 0.3498 - val_accuracy: 0.8630 - val_f1_m: 0.8810\n",
            "Epoch 33/40\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.1756 - accuracy: 0.9741 - f1_m: 0.9800\n",
            "Epoch 00033: val_f1_m did not improve from 0.89157\n",
            "6/6 [==============================] - 2s 295ms/step - loss: 0.1756 - accuracy: 0.9741 - f1_m: 0.9800 - val_loss: 0.3495 - val_accuracy: 0.8630 - val_f1_m: 0.8810\n",
            "Epoch 34/40\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.1545 - accuracy: 0.9710 - f1_m: 0.9694\n",
            "Epoch 00034: val_f1_m did not improve from 0.89157\n",
            "6/6 [==============================] - 2s 293ms/step - loss: 0.1545 - accuracy: 0.9710 - f1_m: 0.9694 - val_loss: 0.3439 - val_accuracy: 0.8630 - val_f1_m: 0.8810\n",
            "Epoch 35/40\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.1409 - accuracy: 0.9817 - f1_m: 0.9774\n",
            "Epoch 00035: val_f1_m did not improve from 0.89157\n",
            "6/6 [==============================] - 2s 292ms/step - loss: 0.1409 - accuracy: 0.9817 - f1_m: 0.9774 - val_loss: 0.3426 - val_accuracy: 0.8630 - val_f1_m: 0.8810\n",
            "Epoch 36/40\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.1387 - accuracy: 0.9771 - f1_m: 0.9821\n",
            "Epoch 00036: val_f1_m did not improve from 0.89157\n",
            "6/6 [==============================] - 2s 290ms/step - loss: 0.1387 - accuracy: 0.9771 - f1_m: 0.9821 - val_loss: 0.3655 - val_accuracy: 0.8493 - val_f1_m: 0.8764\n",
            "Epoch 37/40\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.1228 - accuracy: 0.9863 - f1_m: 0.9895\n",
            "Epoch 00037: val_f1_m did not improve from 0.89157\n",
            "6/6 [==============================] - 2s 292ms/step - loss: 0.1228 - accuracy: 0.9863 - f1_m: 0.9895 - val_loss: 0.3614 - val_accuracy: 0.8082 - val_f1_m: 0.8158\n",
            "Epoch 38/40\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.1248 - accuracy: 0.9863 - f1_m: 0.9897\n",
            "Epoch 00038: val_f1_m did not improve from 0.89157\n",
            "6/6 [==============================] - 2s 296ms/step - loss: 0.1248 - accuracy: 0.9863 - f1_m: 0.9897 - val_loss: 0.3669 - val_accuracy: 0.8493 - val_f1_m: 0.8764\n",
            "Epoch 39/40\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.1065 - accuracy: 0.9893 - f1_m: 0.9922\n",
            "Epoch 00039: val_f1_m did not improve from 0.89157\n",
            "6/6 [==============================] - 2s 290ms/step - loss: 0.1065 - accuracy: 0.9893 - f1_m: 0.9922 - val_loss: 0.3360 - val_accuracy: 0.8630 - val_f1_m: 0.8810\n",
            "Epoch 40/40\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0987 - accuracy: 0.9863 - f1_m: 0.9896\n",
            "Epoch 00040: val_f1_m did not improve from 0.89157\n",
            "6/6 [==============================] - 2s 294ms/step - loss: 0.0987 - accuracy: 0.9863 - f1_m: 0.9896 - val_loss: 0.3519 - val_accuracy: 0.8630 - val_f1_m: 0.8864\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q62_KtZmpGZi"
      },
      "source": [
        "tokenizer_final = Tokenizer(num_words=MAX_NB_WORDS, oov_token=oov_token)\r\n",
        "tokenizer_final.fit_on_texts(df['lemmatized_articles'].values)\r\n",
        "\r\n",
        "X_train_sequences = tokenizer_final.texts_to_sequences(df['lemmatized_articles'].values)\r\n",
        "\r\n",
        "X_train_padded = pad_sequences(X_train_sequences, padding=pad_type, truncating=trunc_type, maxlen=maxlen)\r\n",
        "y_train_final = df['is_adverse_media'].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d4jxjihLtAY6",
        "outputId": "781bd868-d111-48f6-8e69-35e0f7f37496"
      },
      "source": [
        "dependencies = {'f1_m': f1_m}\r\n",
        "best_rnn_simple_model = load_model('weights-improvement-31-0.8916.hdf5', custom_objects=dependencies)\r\n",
        "\r\n",
        "best_rnn_simple_model.fit(x=X_train_padded, \r\n",
        "                          y=y_train_final)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "6/6 [==============================] - 2s 283ms/step - loss: 0.6386 - accuracy: 0.6392 - f1_m: 0.6965\n",
            "Epoch 2/40\n",
            "6/6 [==============================] - 2s 278ms/step - loss: 0.5874 - accuracy: 0.6900 - f1_m: 0.7378\n",
            "Epoch 3/40\n",
            "6/6 [==============================] - 2s 297ms/step - loss: 0.5151 - accuracy: 0.7449 - f1_m: 0.7847\n",
            "Epoch 4/40\n",
            "6/6 [==============================] - 2s 283ms/step - loss: 0.4700 - accuracy: 0.8066 - f1_m: 0.8242\n",
            "Epoch 5/40\n",
            "6/6 [==============================] - 2s 278ms/step - loss: 0.4342 - accuracy: 0.8326 - f1_m: 0.8628\n",
            "Epoch 6/40\n",
            "6/6 [==============================] - 2s 283ms/step - loss: 0.4019 - accuracy: 0.8491 - f1_m: 0.8693\n",
            "Epoch 7/40\n",
            "6/6 [==============================] - 2s 287ms/step - loss: 0.3756 - accuracy: 0.8669 - f1_m: 0.8822\n",
            "Epoch 8/40\n",
            "6/6 [==============================] - 2s 282ms/step - loss: 0.3469 - accuracy: 0.8820 - f1_m: 0.8993\n",
            "Epoch 9/40\n",
            "6/6 [==============================] - 2s 281ms/step - loss: 0.3370 - accuracy: 0.8793 - f1_m: 0.8960\n",
            "Epoch 10/40\n",
            "6/6 [==============================] - 2s 287ms/step - loss: 0.3041 - accuracy: 0.9108 - f1_m: 0.9223\n",
            "Epoch 11/40\n",
            "6/6 [==============================] - 2s 287ms/step - loss: 0.2856 - accuracy: 0.9204 - f1_m: 0.9279\n",
            "Epoch 12/40\n",
            "6/6 [==============================] - 2s 285ms/step - loss: 0.2540 - accuracy: 0.9465 - f1_m: 0.9529\n",
            "Epoch 13/40\n",
            "6/6 [==============================] - 2s 297ms/step - loss: 0.2288 - accuracy: 0.9438 - f1_m: 0.9518\n",
            "Epoch 14/40\n",
            "6/6 [==============================] - 2s 286ms/step - loss: 0.2187 - accuracy: 0.9451 - f1_m: 0.9521\n",
            "Epoch 15/40\n",
            "6/6 [==============================] - 2s 283ms/step - loss: 0.2019 - accuracy: 0.9684 - f1_m: 0.9714\n",
            "Epoch 16/40\n",
            "6/6 [==============================] - 2s 287ms/step - loss: 0.1819 - accuracy: 0.9630 - f1_m: 0.9669\n",
            "Epoch 17/40\n",
            "6/6 [==============================] - 2s 287ms/step - loss: 0.1663 - accuracy: 0.9712 - f1_m: 0.9731\n",
            "Epoch 18/40\n",
            "6/6 [==============================] - 2s 285ms/step - loss: 0.1542 - accuracy: 0.9726 - f1_m: 0.9762\n",
            "Epoch 19/40\n",
            "6/6 [==============================] - 2s 278ms/step - loss: 0.1444 - accuracy: 0.9698 - f1_m: 0.9735\n",
            "Epoch 20/40\n",
            "6/6 [==============================] - 2s 288ms/step - loss: 0.1277 - accuracy: 0.9877 - f1_m: 0.9891\n",
            "Epoch 21/40\n",
            "6/6 [==============================] - 2s 284ms/step - loss: 0.1123 - accuracy: 0.9904 - f1_m: 0.9907\n",
            "Epoch 22/40\n",
            "6/6 [==============================] - 2s 289ms/step - loss: 0.1128 - accuracy: 0.9781 - f1_m: 0.9798\n",
            "Epoch 23/40\n",
            "6/6 [==============================] - 2s 288ms/step - loss: 0.1111 - accuracy: 0.9822 - f1_m: 0.9846\n",
            "Epoch 24/40\n",
            "6/6 [==============================] - 2s 268ms/step - loss: 0.0955 - accuracy: 0.9863 - f1_m: 0.9877\n",
            "Epoch 25/40\n",
            "6/6 [==============================] - 2s 287ms/step - loss: 0.0855 - accuracy: 0.9945 - f1_m: 0.9946\n",
            "Epoch 26/40\n",
            "6/6 [==============================] - 2s 287ms/step - loss: 0.0814 - accuracy: 0.9931 - f1_m: 0.9931\n",
            "Epoch 27/40\n",
            "6/6 [==============================] - 2s 281ms/step - loss: 0.0767 - accuracy: 0.9918 - f1_m: 0.9932\n",
            "Epoch 28/40\n",
            "6/6 [==============================] - 2s 284ms/step - loss: 0.0685 - accuracy: 0.9959 - f1_m: 0.9958\n",
            "Epoch 29/40\n",
            "6/6 [==============================] - 2s 283ms/step - loss: 0.0691 - accuracy: 0.9904 - f1_m: 0.9917\n",
            "Epoch 30/40\n",
            "6/6 [==============================] - 2s 273ms/step - loss: 0.0601 - accuracy: 0.9959 - f1_m: 0.9967\n",
            "Epoch 31/40\n",
            "6/6 [==============================] - 2s 279ms/step - loss: 0.0527 - accuracy: 0.9986 - f1_m: 0.9984\n",
            "Epoch 32/40\n",
            "6/6 [==============================] - 2s 290ms/step - loss: 0.0528 - accuracy: 0.9945 - f1_m: 0.9950\n",
            "Epoch 33/40\n",
            "6/6 [==============================] - 2s 288ms/step - loss: 0.0492 - accuracy: 1.0000 - f1_m: 1.0000\n",
            "Epoch 34/40\n",
            "6/6 [==============================] - 2s 283ms/step - loss: 0.0436 - accuracy: 1.0000 - f1_m: 1.0000\n",
            "Epoch 35/40\n",
            "6/6 [==============================] - 2s 283ms/step - loss: 0.0451 - accuracy: 0.9986 - f1_m: 0.9990\n",
            "Epoch 36/40\n",
            "6/6 [==============================] - 2s 274ms/step - loss: 0.0392 - accuracy: 1.0000 - f1_m: 1.0000\n",
            "Epoch 37/40\n",
            "6/6 [==============================] - 2s 274ms/step - loss: 0.0384 - accuracy: 0.9986 - f1_m: 0.9988\n",
            "Epoch 38/40\n",
            "6/6 [==============================] - 2s 287ms/step - loss: 0.0362 - accuracy: 1.0000 - f1_m: 1.0000\n",
            "Epoch 39/40\n",
            "6/6 [==============================] - 2s 291ms/step - loss: 0.0327 - accuracy: 1.0000 - f1_m: 1.0000\n",
            "Epoch 40/40\n",
            "6/6 [==============================] - 2s 283ms/step - loss: 0.0340 - accuracy: 0.9986 - f1_m: 0.9989\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f7712cf6550>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2SEsF_I1qDLZ"
      },
      "source": [
        "df_test = pd.read_csv('public_test.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n-z0_2zdp8-1",
        "outputId": "9d0bd25f-0a81-4b82-b48c-1f8c46f91cf1"
      },
      "source": [
        "X_test_sequences = tokenizer_final.texts_to_sequences(df_test['article'].values)\r\n",
        "\r\n",
        "X_test_padded = pad_sequences(X_test_sequences, padding=pad_type, truncating=trunc_type, maxlen=maxlen)\r\n",
        "y_test = df_test['label'].values\r\n",
        "\r\n",
        "\r\n",
        "y_test_pred = best_rnn_simple_model.predict(X_test_padded, verbose=1)\r\n",
        "y_test_pred = y_test_pred.reshape(y_test_pred.shape[0],)\r\n",
        "y_test_pred = np.array([1 if p>=0.5 else 0 for p in y_test_pred])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 0s 19ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y9kzY1YiqeyH"
      },
      "source": [
        "auc_without_glove = roc_auc_score(y_test, y_test_pred)\r\n",
        "accuracy_without_glove = accuracy_score(y_test, y_test_pred)\r\n",
        "f1_without_glove  = f1_score(y_test, y_test_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HzyN0Z6oqgmU",
        "outputId": "b85ddc8c-e87a-4b42-f24b-ad442670d156"
      },
      "source": [
        "print(auc_without_glove, accuracy_without_glove, f1_without_glove)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8014632524110409 0.7861635220125787 0.8068181818181818\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
